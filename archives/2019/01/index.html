<!DOCTYPE html>
<html lang="zh-cmn-Hans" prefix="og: http://ogp.me/ns#" class="han-init">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <link rel="icon" href="/favicon.ico">
  
  <title>李晓杰的个人博客</title>
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/lib/fancybox/jquery.fancybox-1.3.4.css">
  <!--在这里倒入jquery 方便处理部分页面的jquery-->
  <script src="https://cdn.staticfile.org/jquery/1.7/jquery.min.js" type="text/javascript"></script>
</head></html>
<body class="home">
	<header class="site-header navfixed-false">
  <div class="container">
      <h1><a href="/" title="李晓杰的个人博客"><span class="octicon octicon-mark-github"></span> 李晓杰的个人博客</a></h1>
      <nav class="site-header-nav" role="navigation">
        
              
              <a href="/" class=" site-header-nav-item hvr-underline-from-center" title="主页">主页</a>
        
              
              <a href="/categories/" class=" site-header-nav-item hvr-underline-from-center" title="分类">分类</a>
        
              
              <a href="/message/" class=" site-header-nav-item hvr-underline-from-center" title="留言">留言</a>
        
      </nav>
  </div>
</header>

	<section class="banner-false">
    <div class="collection-head">
        <div class="container">
            <div class="collection-title">
                <h1 class="collection-header" id="site-description">
                    
                </h1>
                <div class="collection-info">
                    
                    
                        <span class="meta-info">
                            
                                <span class="octicon octicon-location">
                                   
                                        北京, 中国
                                    
                                </span>
                                
                            
                        </span>
                    
                        <span class="meta-info">
                            
                                <span class="octicon octicon-mark-github">
                                   
                                </span>
                                
                                    <a href="http://github.com/lixiaojiee" target="_blank">lixiaojiee</a>
                                
                            
                        </span>
                    
                </div>
            </div>
        </div>
    </div>
</section>
	   <section class="container">
    <div class="columns">
        <div class="column two-thirds">
            
                  <article id="post-redis/redis学习之慢查询分析" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <h1 id="一、慢查询分析"><a href="#一、慢查询分析" class="headerlink" title="一、慢查询分析"></a>一、慢查询分析</h1><p>1、redis客户端执行一条命令分为如下4个部分：</p>
<p>1）发送命令</p>
<p>2）命令排队</p>
<p>3）命令执行</p>
<p>4）返回结果</p>
<p>慢查询只统计3）的时间，1）+4）称为Round Trip Time（RTT，往返时间）所以没有慢查询并不代表客户端没有超时问题</p>
<p>慢查询的两个配置参数：</p>
<p><code>showlog-log-slower-than</code>:预设的阈值，单位为微秒，默认为10 000，超过预设阈值的查询操作将会被记录进慢查询日志中</p>
<p><code>showlog-max-len</code>:慢查询日志列表的最大长度，当慢查询日志列表已处于其最大长度时，最早插入的一个命令将从列表中移出</p>
<p>redis中有两种修改配置的方法，一种是修改配置文件，另一种是使用config set命令动态修改。如下所示：</p>
<pre><code>config set showlog-log-slower-than 20000
config set showlog-max-len 1000
config rewrite #将修改的配置持久化到本地配置文件中
</code></pre><p>2、慢查询日志的访问和管理</p>
<p>1）获取慢查询日志</p>
<pre><code>showlog get [n]
</code></pre><p>慢查询日志的组成：</p>
<p>a、标识id</p>
<p>b、发生的时间戳</p>
<p>c、命令耗时</p>
<p>d、执行的命令和参数</p>
<p>2）获取慢查询日志列表的当前长度</p>
<pre><code>showlog len
</code></pre><p>3)慢查询日志重置</p>
<pre><code>showlog reset
</code></pre><p>3、关于慢查询的相关建议</p>
<p>a、showlog-max-len配置建议：线上建议调大慢查询列表，记录慢查询时redis会对长命令做截断操作，并不会占用大量内存。增大慢查询列表可以减缓慢查询被剔除的可能</p>
<p>b、showlog-log-slower-than配置建议：默认值超过10毫秒判定为慢查询，需要根据redis并发量调整该值。</p>
<p>c、慢查询只记录命令执行时间，并不包括命令排队和网络传输时间，因此客户端执行命令的时间会大于命令实际执行的时间。因为命令执行的排队机制，慢查询会导致其他命令级联阻塞，因此当客户端出现请求超时，需要检查该时间点是否有对应的慢查询，从而分析是否为慢查询导致命令级联阻塞</p>
<p>d、由于慢查询日志是一个先进先出的队列，也就是说在慢查询比较多的情况下，可能会丢失部分慢查询命令，为了防止这种情况的发生，可以定期执行showlog get命令将慢查询日志持久化到其他存储中，然后可以制作可视化界面进行查询。 </p>
<h1 id="二、Pipeline"><a href="#二、Pipeline" class="headerlink" title="二、Pipeline"></a>二、Pipeline</h1><p>pipeline可以将一组redis命令进行组装，通过一次RTT传输给redis，再将这组redis命令的执行结果按顺序返回给客户端</p>
<p>原生批量命令与pipeline对比：</p>
<ul>
<li>原生批量命令是原子的，pipeline是非原子的</li>
<li>原生批量命令是一个命令对应多个key，pipeline支持多个命令</li>
<li>原生批量命令是redis服务端支持实现的，而pipeline需要服务端和客户端的共同实现</li>
</ul>
<p>pipeline组装的命令个数不能没有节制，否则一次组装pipeline数据过大，一方面会增加客户端的等待时间，另一方面会造成一定的网络阻塞</p>
<p>pipeline只能操作一个redis实例</p>
<h1 id="三、事物与LUA"><a href="#三、事物与LUA" class="headerlink" title="三、事物与LUA"></a>三、事物与LUA</h1><h2 id="1、事物"><a href="#1、事物" class="headerlink" title="1、事物"></a>1、事物</h2><p>redis提供了简单事物功能，将一组需要一起执行的命令放到<code>multi</code>和<code>exec</code>两个命令之间。<code>multi</code>命令代表事物开始，<code>exec</code>命令代表事物结束，它们之间的命令是原子顺序执行的，每执行完一条指令，返回结果为QUEUED，代表命令并没有真正执行，而是暂时保存在redis。只有执行<code>exec</code>命令后，两个操作才真正执行，事物执行结束后，会返回各个操作的执行结果，如果结果为nil，则说明事物没有执行</p>
<p>如果要停止事物的执行，可以使用<code>discard</code>命令代替<code>exec</code>命令即可。</p>
<p>如果事物中的命令出现错误，redis也有不同的处理机制：</p>
<p>1）命令错误，比如命令拼写错误，会造成整个事物无法执行，事物不回滚</p>
<p>2）运行时错误，比如zdd写成了sadd，也会造成事物无法运行，但是事物不会回滚</p>
<p>有时在事物之前，确保事物中的key没有被其他客户端修改过，才执行事物，否则不执行。redis提供了<code>watch</code>命令来解决这个问题</p>
<p>之所以说redis只是支持简单事物，就是因为其不支持事物的回滚特性。</p>
<h2 id="2、LUA用法"><a href="#2、LUA用法" class="headerlink" title="2、LUA用法"></a>2、LUA用法</h2><h3 id="1）数据类型及其逻辑处理"><a href="#1）数据类型及其逻辑处理" class="headerlink" title="1）数据类型及其逻辑处理"></a>1）数据类型及其逻辑处理</h3><p>a、字符串（strings）</p>
<pre><code class="lua">local strings val = &quot;world&quot;
</code></pre>
<p>local代表val是一个局部变量，如果没有local，则代表是全局变量。</p>
<p>2）数组（tables）</p>
<pre><code class="lua">local tables myArray == {&quot;redis&quot;, &quot;jedis&quot;, true, 88.0}
</code></pre>
<p>lua的数组下标从1开始计算</p>
<p>如果想要遍历这个数组，可以使用for和while。</p>
<p>a、for</p>
<pre><code class="lua">--计算2）中数组的长度
for i = 1, #myArray
do
    print(myArray[i])
end
</code></pre>
<p>要获取数组的长度，只需在数组的变量前加#</p>
<p>除此之外，lua还提供了内置函数ipairs，使用for index,value ipairs(tables)可以遍历出所有的索引下标和值，如下：</p>
<pre><code class="lua">for index,value in ipairs(myArray)
do
    print(index)
    print(value)
end
</code></pre>
<p>b、while</p>
<p>计算1到100的和</p>
<pre><code class="lua">--求1到100的和
local int num = 0
local int i = 0
while i &lt;= 100
do
    sum = sum + i
    i = i + 1
end
--输出求和结果
print(num)
</code></pre>
<p>c、if-else</p>
<pre><code class="lua">local tables myArray = {&quot;redis&quot;, &quot;jedis&quot;, true, 88.0}
for i = 1, #myArray
do
    if myArray[i] == &quot;jedis&quot;
    then
        print(&quot;true&quot;)
           break
    else
        --do nothing
    end
end
</code></pre>
<p>3)哈希</p>
<p>数组中的每个元素都是键值对组合</p>
<pre><code class="lua">local tables user = {age = 28, name= &quot;lixiaojie&quot;}
</code></pre>
<p>遍历哈希</p>
<pre><code class="lua">for key,value in pairs(user)
do 
    print(key .. value)
end
</code></pre>
<h3 id="2-函数定义"><a href="#2-函数定义" class="headerlink" title="2)函数定义"></a>2)函数定义</h3><p>在lua中，函数以function开头，以end结尾，functionName为函数名，中间部分是函数体</p>
<pre><code class="lua">function functionName()
    ...
end
</code></pre>
<h2 id="3-在redis中使用lua"><a href="#3-在redis中使用lua" class="headerlink" title="3)在redis中使用lua"></a>3)在redis中使用lua</h2><p>在redis中使用lua脚本有两种方法：<code>eval</code>和<code>evalsha</code></p>
<p>a、eval</p>
<pre><code class="shell">eval 脚本内容 key个数 key列表 参数列表
</code></pre>
<p>示例：</p>
<pre><code class="shell">eval &#39;return &quot;hello &quot; .. KEYS[1] .. ARGV[1]&#39; 1 redis word
</code></pre>
<p>结果为:hello redisword</p>
<p>如果lua脚本过长，还可以使用redis-cli –eval直接执行文件</p>
<p>eval命令和–eval参数本质是一样的，客户端如果想执行lua脚本，首先在客户端编写好lua脚本代码，然后把脚本作为字符串发送给服务端，服务端会执行结果返回给客户端</p>
<p>b、evalsha</p>
<p>首先要将lua脚本加载到redis服务端，得到该脚本的SHA1校验和，evalsha命令使用SHA1作为参数可以直接执行对应的lua脚本，避免每次发送lua脚本的开销。这样客户端就不需要每次执行脚本内容，而脚本也会常驻服务端，脚本功能得到复用</p>
<p><strong>加载脚本：</strong>script load命令可以将脚本内容加载到redis内存中</p>
<p><strong>执行脚本：</strong>evalsha的使用方法如下，参数使用SHA1值，执行逻辑和eval一致</p>
<pre><code class="shell">evalsha 脚本 SHA1值 key个数 key列表 参数列表
</code></pre>
<p>lua脚本功能有三个好处：</p>
<ul>
<li>lua脚本在redis中是原子执行的，执行过程中间不会插入其它命令</li>
<li>可以定制自己的命令，并可以将这些命令常驻在red is 内存中</li>
<li>lua脚本可以将多条命令一次性打包，有效减少网络开销</li>
</ul>
<p>redis如何管理lua脚本：</p>
<p>a、script load</p>
<pre><code>script load script
</code></pre><p>此命令用于将lua脚本加载到redis内存中</p>
<p>b、script exists</p>
<pre><code>script exists sha1 [sha1 ...]
</code></pre><p>此命令用来判断指定sha1是否已经加载到redis里，返回的结果代表sha1被加载到内存中的个数</p>
<p>c、script flush</p>
<pre><code>script flush
</code></pre><p>此命令用于清除redis内存已经加载的所有lua脚本</p>
<p>d、script kill</p>
<pre><code>script kill
</code></pre><p>此命令用于杀掉正在执行的lua脚本，如果lua脚本比较耗时，甚至lua脚本存在问题，那么此时lua脚本的执行会阻塞redis，直到脚本执行完毕或着外部进行干预将其结束</p>
<p>如果当前脚本正在执行写操作，那么<code>script kill</code>命令将不会生效。 </p>
<h2 id="4）Bitmaps"><a href="#4）Bitmaps" class="headerlink" title="4）Bitmaps"></a>4）Bitmaps</h2><p>Bitmaps是一种redis实现的位操作的“数据结构”</p>
<ul>
<li>Bitmaps本身不是一种数据结构，实际上它就是字符串，但是它可以对字符串的位进行操作</li>
<li>Bitmaps单独提供了一套命令，所以在Redis中使用Bitmaps和使用字符串的方法不太相同。可以把Bitmaps想象成一个以位为单位的数组，数组的每个单元只能存储0和1，数组的下标在Bitmaps中叫偏移量</li>
</ul>
<p>a、命令</p>
<p>i、设置值</p>
<pre><code>setbit key offset value
</code></pre><p>设置键的第offset个位的值（从0开始算）</p>
<p>很多用户id以一个指定的数字开头，直接将用户id和bitmaps的偏移量对应势必会造成一定的浪费，通常的做法是每次做setbit操作时将用户id减去这个指定的数字。在第一次初始化Bitmaps时，加入偏移量非常大，那么整个初始化过程执行会比较慢，可能会造成Redis阻塞</p>
<p>ii、获取值</p>
<pre><code>getbit key offset
</code></pre><p> 获取键的第offset位的值（从0开始算）</p>
<p>iii、获取Bitmaps指定范围值为1的个数</p>
<pre><code>bitcount [start] [end]
</code></pre><p>[start]和[end]代表起始和结束子节数</p>
<p>iv、Bitmaps间的运算</p>
<pre><code>bitop op destkey key [key1 ..]
</code></pre><p>bitop是一个符合操作，它可以做多个Bitmaps的and（交集）、or（并集）、not（非）、xor（异或）操作并将结果保存在destkey中</p>
<p>v、计算Bitmaps中第一个值为targetBit的偏移量</p>
<pre><code>bitops key targetBit [start] [end]
</code></pre><p>  Bitmaps相比于set的优缺点：</p>
<p>1）Bitmaps存储活跃用户统计是用位统计，相比于set要节省很多空间</p>
<p>2）如果有很多非活跃用户，Bitmaps的优势就不那么明显了</p>
<h2 id="5）HyperLogLog"><a href="#5）HyperLogLog" class="headerlink" title="5）HyperLogLog"></a>5）HyperLogLog</h2><p>HyperLogLog并不是一种新的数据结构（实际类型为字符串类型），而是一种基数算法，通过HyperLogLog可以利用极小的空间完成独立总数的统计，数据集可以是IP、Email、ID等</p>
<p>命令：</p>
<p>i、添加</p>
<pre><code>pfadd key element [element1 ...]
</code></pre><p>pfadd用于向HyperLogLog添加元素，如果添加成功则返回1</p>
<p>ii、计算独立用户数</p>
<pre><code>pfcount key [key1 ...]
</code></pre><p>pfcount用于计算一个或多个HyperLogLog的独立总数</p>
<p>iii、合并</p>
<pre><code>pfmerge destkey sourcekey [sourcekey1 ...]
</code></pre><p>pfmerge可以求出多个HyperLogLog的并集并赋值给destkey</p>
<p>HyperLogLog内存占用量非常小，但是存在错误率，开发者在进行数据结构选型时只需要确认如下两条即可：</p>
<ul>
<li>只为了计算独立总数，不需要获取单条数据</li>
<li>剋容忍一定的误差率，毕竟HyperLogLog在内存的占用量上有很大的优势</li>
</ul>
<h2 id="6）发布订阅"><a href="#6）发布订阅" class="headerlink" title="6）发布订阅"></a>6）发布订阅</h2><p>Redis提供了基于“发布/订阅”模式的消息机制，此种模式下消息发布者和订阅者不进行直接通信，发布者客户端向指定频道（channel）发布消息，订阅该频道的每个客户端都可以收到该消息</p>
<p>常用命令：</p>
<p>i、发布消息</p>
<pre><code>publish channel message
</code></pre><p>返回结果为订阅者个数</p>
<p>ii、订阅消息</p>
<pre><code>subscribe channel [channel1 ...]
</code></pre><p>订阅消息有以下几点需要注意：</p>
<ul>
<li>客户端在执行订阅命令后进入了订阅状态，只能接收subscribe、psubscribe、unsubscribe、punsubscribe的四个命令</li>
<li>新开启的订阅客户端，无法收到该频道之前的消息，因为Redis不会对发布的消息进行持久化</li>
</ul>
<p>iii、取消订阅</p>
<pre><code>unsubscribe [channel [channel1 ...]]
</code></pre><p>iv、按照模式进行订阅和取消订阅</p>
<pre><code>psubscribe pattern [pattern1 ...]
punsubscribe pattern [pattern1 ...]
</code></pre><p>v、查询订阅</p>
<p>查看活跃的频道</p>
<pre><code>pubsub channels [pattern]
</code></pre><p>所谓活跃的频道是指当前频道至少有一个订阅者，其中pattern是指具体的模式</p>
<p>查看频道订阅数</p>
<pre><code>pubsub numsub [channel ...]
</code></pre><p>查看模式订阅数</p>
<pre><code>pubsub numpat
</code></pre><p>也就是查看通过模式订阅的客户端数</p>
<p>使用场景：</p>
<p>聊天室、公告牌、服务之间利用消息进行解藕</p>
<h2 id="7、GEO"><a href="#7、GEO" class="headerlink" title="7、GEO"></a>7、GEO</h2><p>GEO支持存储地理位置信息用来实现诸如附近位置、摇一摇这类依赖于地理位置信息的功能</p>
<p>常用命令：</p>
<p>i、添加地理位置信息</p>
<pre><code>geoadd key longitude latitude memer [longitude1 latitude1 member1 ...]
</code></pre><p>Longitude、latitude和member分别是该地理位置的经度、纬度、成员，返回的结果为成功添加的个数，如果集合中没有，添加时返回为1，如果已经有了，再添加，则返回0</p>
<p>如果需哟啊更新地理位置信息，仍然可以使用geoadd命令，虽然返回的结果是0。</p>
<p>ii、获取地理位置信息</p>
<pre><code>geopos key member [member1 ...]
</code></pre><p>iii、获取两个地理位置的距离</p>
<pre><code>geodist key member1 member2 [unit]
</code></pre><p>其中unit代表返回结果的单位，包含以下四种：</p>
<ul>
<li>m（meters）代表米</li>
<li>km（kilometers）代表千米</li>
<li>mi（miles）代表英里</li>
<li>ft（feet）代表尺</li>
</ul>
<p>iv、获取指定位置范围内的地理信息位置集合</p>
<pre><code>georadius key longitude latitude radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key]
getradiusbymember key member longitude latitude radiusm|km|ft|mi [withcoord] [withdist] [withhash] [COUNT count] [asc|desc] [store key] [storedist key]
</code></pre><p>georadius和georadiusbymember两个命令的作用是一样的，都是以一个地理位置为中心算出指定半径内的其它地理信息位置，不同的是georadius命令的中心位置给出了具体的经纬度，georadiusbymember只需要给出成员即可，其中radiusm|km|ft|mi是必须参数，指定了半径，这两个命令有很多参数可选，如下：</p>
<ul>
<li>withcoord：返回结果中包含经纬度</li>
<li>withdist：返回结果中包含离中心节点位置的距离</li>
<li>withhash：返回结果中包含geohash</li>
<li>COUNT count：指定返回结果的数量</li>
<li>asc|desc： 返回结果按照离中心节点的距离做升序或者降序</li>
<li>store key： 将返回的结果的地理位置信息保存到指定的键</li>
<li>storedist key：将返回结果离中心的距离保存到指定键</li>
</ul>
<p>v、获取geohash</p>
<pre><code>geohash key member [member1 ...]
</code></pre><p>将二维经纬度转换成一维字符串</p>
<p>geohash有如下特点：</p>
<ul>
<li>GEO的数据类型为zset，redis将所有的地理位置信息的geohash存放在zset中</li>
<li>字符串越长，表示的位置更精确</li>
<li>两个字符串越相似，它们之间的距离越近，redis利用字符串的前缀匹配算法实现相关的命令</li>
<li>geohash编码和经纬度是可以相互转换的</li>
</ul>
<p>vi、删除地理位置信息</p>
<pre><code>zrem key member
</code></pre><p>借用zset的zrem命令，因为其底层实现是zset</p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.144Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/redis学习之持久化" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <p>redis支持AOF和RDB两种持久化机制。</p>
<h1 id="一、RDB"><a href="#一、RDB" class="headerlink" title="一、RDB"></a>一、RDB</h1><p>RDB持久化是把当前进程数据生成的快照保存到硬盘的过程，触发RDB持久化过程分为手动触发和自动触发</p>
<h2 id="1、触发机制"><a href="#1、触发机制" class="headerlink" title="1、触发机制"></a>1、触发机制</h2><p>手动触发分别对应<code>save</code>和<code>bgsave</code>命令：</p>
<ul>
<li>save命令：阻塞当前redis服务器，知道RDB过程完成为止，杜宇内存比较大的实例会造成场时间的阻塞，线上环境不建议使用</li>
<li>bgsave命令：redis进程执行fork操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。阻塞只发生在fork阶段，一般时间很短</li>
</ul>
<h2 id="2、哪些场景会触发bgsave操作"><a href="#2、哪些场景会触发bgsave操作" class="headerlink" title="2、哪些场景会触发bgsave操作"></a>2、哪些场景会触发bgsave操作</h2><ul>
<li>使用save相关配置，如“save m n”，表示m秒内数据集存在n次修改时，自动触发<code>bgsave</code></li>
<li>如果从节点执行全量复制操作，祝节点自动执行<code>bgsave</code>生成RDB文件并发送给从节点</li>
<li>执行<code>debug reload</code>命令重新加载redis时，也会自动触发save操作</li>
<li>默认情况下执行<code>shutdown</code>命令时，如果没有开启AOF持久化功能则自动执行bgsave</li>
</ul>
<h3 id="3、处理流程"><a href="#3、处理流程" class="headerlink" title="3、处理流程"></a>3、处理流程</h3><ul>
<li>执行<code>bgsave</code>命令，redis父进程判断当前是否存在正在执行的子进程，如RDB/AOF子进程，如果存在<code>bgsave</code>命令直接退出</li>
<li>父进程执行fork操作创建子进程，fork操作过程中父进程会阻塞</li>
<li>子进程创建RDB文件，根据父进程内存生成临时快照文件，完成后对原有文件进行原子替换</li>
<li>子进程发送信号给父进程表示完成，父进程更新统计信息</li>
</ul>
<h3 id="4、RDB文件的处理"><a href="#4、RDB文件的处理" class="headerlink" title="4、RDB文件的处理"></a>4、RDB文件的处理</h3><h4 id="1）保存"><a href="#1）保存" class="headerlink" title="1）保存"></a>1）保存</h4><p>RDB文件保存在dir配置指定的目录下，文件名通过dbfilename配置指定</p>
<h4 id="2-压缩"><a href="#2-压缩" class="headerlink" title="2)压缩"></a>2)压缩</h4><p>redis默认采用LZF算法对生成的RDB文件进行压缩处理，压缩后的文件远远小于内存大小，默认开启</p>
<h4 id="3）校验"><a href="#3）校验" class="headerlink" title="3）校验"></a>3）校验</h4><p>如果redis加载损坏的RDB文件时会拒绝启动</p>
<h3 id="5、RDB的优缺点"><a href="#5、RDB的优缺点" class="headerlink" title="5、RDB的优缺点"></a>5、RDB的优缺点</h3><p>优点：</p>
<p>1）RDB是一个紧凑压缩的二进制文件，代表redis在某个时间点上的数据快照。非常适用于备份、全量复制等场景</p>
<p>2）redis加载RDB恢复数据远远快于AOF的方式</p>
<p>缺点：</p>
<p>1）RDB方式数据没办法做到实时持久化/秒级持久化。因为bgsave每次运行都要执行fork操作创建子进程，属于重量级操作，频繁执行成本过高</p>
<p>2）RDB文件使用特定二进制格式保存，redis版本演进过程中有多个格式的RDB版本，存在老版本redis服务无法兼容新版本RDB格式的问题</p>
<h1 id="二、AOF"><a href="#二、AOF" class="headerlink" title="二、AOF"></a>二、AOF</h1><p>AOF持久化（append only file）持久化：以独立日志的方式记录每次写命令，重启时再重新执行AOF文件中的命令达到恢复数据的目的。</p>
<p>AOF的主要作用时解决了数据持久化的实时性，目前已经过时redis持久化的主流方式</p>
<h2 id="1、使用AOF"><a href="#1、使用AOF" class="headerlink" title="1、使用AOF"></a>1、使用AOF</h2><p> 开启AOF功能需要设置配置：<code>appendonly yes</code>，默认不开启。AOF文件名通过appendfilename配置设置，默认文件名时appendonly.aof。保存路径与RDB持久化方式一致。</p>
<p>AOF的工作流程如下：</p>
<ul>
<li>所有的写入命令会追加到aof_buf（缓冲区）中</li>
<li>AOF缓冲区根据对一个的策略向硬盘做同步操作</li>
<li>随着AOF文件越来越大，需要定期对AOF文件进行重写，达到压缩的目的</li>
<li>当redis服务器重启时，可以加载AOF文件进行数据恢复</li>
</ul>
<h2 id="2、文件同步"><a href="#2、文件同步" class="headerlink" title="2、文件同步"></a>2、文件同步</h2><p>redis提供了多种AOF缓冲区同步文件策略，由参数appendfsync控制，分别如下所示：</p>
<ul>
<li>配置为always时，每次可入都要同步AOF文件，在一般的STAT硬盘上，redis只能支持大约几百TPS的写入，不建议配置</li>
<li>配置为no，由于操作系统每次同步AOF文件的周期不可控，而且会加大每次同步硬盘的数据量，虽然提升了性能，但数据的安全性无法保证</li>
<li>配置为everysec，这个是建议的配置策略，也是默认的配置，做到兼顾性能和数据安全性。理论上只有在系统突然宕机的情况下丢失1秒的数据</li>
</ul>
<h2 id="3、重写机制"><a href="#3、重写机制" class="headerlink" title="3、重写机制"></a>3、重写机制</h2><p>随着命令不断 写入AOF，文件会越来越大，为了解决这个问题，redis引入AOF重写机制压缩文件体积。==AOF重写是把redis进程内的数据转化为写命令同步到新AOF文件的过程==</p>
<p>重写后的文件为什么可以变小？</p>
<ul>
<li>进程内已经超时的数据不再写入文件</li>
<li>旧的AOF文件含有无效命令，如del key1、hdel key2、 srem keys、 set a 111、set a 222等。重写使用进程内数据直接生成，这样新的AOF文件只保留最终的写入命令</li>
<li>多条写命令可以合并为一个，如lpush list a、lpush list b可以转化为lpush list a b。为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、zset、hash等类型的操作，以64个元素为界拆分为多条</li>
</ul>
<p>AOF重写降低了文件的占用空间，还有一个目的就是，更小的AOF文件可以更快的被redis加载</p>
<p>AOF重写可以手动触发和自动触发：</p>
<p>1）手动触发：直接调用bgrewriteaof命令</p>
<p>2）自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数确定自动触发时机</p>
<ul>
<li>auto-aof-rewrite-min-size：表示运行AOF重写时文件最小体积，默认为64MB</li>
<li>auto-aof-rewrite-percentage：当前AOF文件空间和上一次重写后AOF文件空间的比值</li>
</ul>
<p>当当前AOF空间大于设置的最小体积且空间比大于等于设置的空间比时，会触发重写</p>
<p>AOF重写的流程：</p>
<p>1）执行AOF重写请求</p>
<ul>
<li>如果当前进程正在执行AOF重写，则请求不执行</li>
<li>如果当前进程正在执行bgsave操作，重写命令延迟到bgsave完成之后再执行</li>
</ul>
<p>2）父进程执行fork创建子进程，开销等同于bgsave过程</p>
<p>3）主进程fork操作完成后，继续响应其它命令。所有修改命令依然写入AOF缓冲区并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确性</p>
<p>由于fork操作运用了写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然响应命令，redis使用“AOF重写缓冲区”保存这部分新数据，防止新AOF文件生成期间丢失这部分数据</p>
<p>4）子进程根据内存快照，按照命令合并规则写入到新的AOF文件</p>
<p>5）新AOF文件写入完成后，子进程发送信号给父进程，父进程更新统计信息</p>
<p>父进程把AOF重写缓冲区的数据写入到新的AOF文件</p>
<p>使用新AOF文件替换老文件，完成AOF重写</p>
<h2 id="4、重启加载"><a href="#4、重启加载" class="headerlink" title="4、重启加载"></a>4、重启加载</h2><p>AOF和RD文件都可用于服务器重启时的数据恢复</p>
<p>流程如下：</p>
<p>1）AOF持久化开启且存在AOF文件时，优先加载AOF文件</p>
<p>2）AOF关闭或者AOF文件不存在时，加载RDB文件</p>
<p>3）加载AOF/RDB文件成功后，redis启动成功</p>
<p>4）AOF/RDB文件存在错误时，redis启动失败并打印错误日志 </p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.143Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/redis学习之理解内存" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <h1 id="一、内存消耗"><a href="#一、内存消耗" class="headerlink" title="一、内存消耗"></a>一、内存消耗</h1><h2 id="1、内存消耗的划分"><a href="#1、内存消耗的划分" class="headerlink" title="1、内存消耗的划分"></a>1、内存消耗的划分</h2><p>Redis进程内消耗主要包括：自身内存+对象内存+缓冲内存+内存碎片,如下图所示：</p>
<p><img src="/Users/lixiaojie/github/study/pictures/redis内存消耗划分-1.png.png" alt=""></p>
<p>1）对象内存是redis内存占用最大的一块，存储着用户所有的数据</p>
<p>redis所有的数据都是采用k-v数据类型，每次创建键值对时，至少创建两种类型的对象，键对象使用的是字符串，在使用redis时很容易忽略健对内存消耗的影响，应当避免使用过长的键。value对象复杂些，包括五种数据类型。其他数据类型都是建立在这五种数据类型之上实现的，如Bitmaps和HyperLogLog都是使用字符串实现，GEO使用有序集合实现等。</p>
<p>2）缓冲内存：</p>
<p>缓冲区内存主要包括<strong>客户端缓冲</strong>、<strong>复制积压区缓冲区</strong>、<strong>AOF缓冲区</strong></p>
<p><strong>客户端缓冲</strong>指的是所有接入redis服务器的tcp链接的输入输出缓冲。输入缓冲无法控制，最大空间1G，如果超过将断开连接，输出缓冲通过参数client-output-buffer-limit控制</p>
<p><strong>复制积压缓冲区</strong>整个redis主节点只有一个，所有的从节点共享此缓冲区，因此可以设置较大的缓冲区空间，以防止全量复制</p>
<p><strong>AOF缓冲区</strong>：这部分空间用于在redis重谢期间保存最近的写入命令。AOF缓冲区用户无法控制，消耗的内存取决于AOF充血时间和写入命令量，这部分空间通常占用很小</p>
<p>3）内存碎片：</p>
<p>以下操作会引起高内存碎片问题：</p>
<p>a、频繁做更新操作</p>
<p>b、大量过期键删除，键对象过期删除后，释放的空间无法得到充分利用，导致碎片率上升</p>
<p>高碎片率的常见解决办法：</p>
<p>a、数据对齐，在条件允许的情况下尽量做数据对齐，比如数据尽量采用数字类型或者固定长度字符串等</p>
<p>b、安全重启：重启节点可以做到内存碎片重新整理，因此可以利用高可用架构，如Sentinel或Cluster，将碎片率过高的主节点转换为从节点，进行安全重启</p>
<p>子进程内存消耗</p>
<p>子进程内存消耗主要指执行AOF/RDB重写时redis创建的子进程内存消耗</p>
<h1 id="二、内存管理"><a href="#二、内存管理" class="headerlink" title="二、内存管理"></a>二、内存管理</h1><h2 id="1、设置内存上限"><a href="#1、设置内存上限" class="headerlink" title="1、设置内存上限"></a>1、设置内存上限</h2><p>redis可以泗洪maxmemory参数限制最大可用内存。限制内存的主要目的由：<br>1）用于缓存系统，当超出内存上限maxmemory时适用LRU等删除策略释放空间</p>
<p>2）防止所有内存超过服务器物理内存</p>
<h2 id="2、动态调整内存上限"><a href="#2、动态调整内存上限" class="headerlink" title="2、动态调整内存上限"></a>2、动态调整内存上限</h2><p>redis的内存上限可以通过<code>config set maxmemory</code>进行动态修改，即修改最大可用内存，通过动态修改内存，可以实现在当前服务器下动态伸缩redis内存的目的</p>
<p><u>redis默认无限适用服务器内存，为防止极端情况下导致系统内存耗尽，建议所有的redis进程都要配置maxmemory</u></p>
<h2 id="3、内存回收策略"><a href="#3、内存回收策略" class="headerlink" title="3、内存回收策略"></a>3、内存回收策略</h2><p>redis的内存回收机制主要体现在以下两个方面：</p>
<ul>
<li>删除到达过期时间的键对象</li>
<li>内存使用达到maxmemory上限时触发内存溢出控制策略</li>
</ul>
<h3 id="1）删除过期键对象"><a href="#1）删除过期键对象" class="headerlink" title="1）删除过期键对象"></a>1）删除过期键对象</h3><p>​    redis进程内保存大量的键，维护每个键精准的过期删除机制会导致消耗大量的CPU，这对于单线程的redis来说成本过高，因此redis采用惰性删除和定时任务删除机制实现过期键的内存回收</p>
<p><strong>a、惰性删除：</strong></p>
<p>惰性删除用于当客户端读取带有超时属性的键时，如果已经超过键设置的过期时间，会执行删除操作并返回空，这种策略处于节省CPU考虑，不需要单独维护TTL链表来处理过期键的删除。但是单独使用这种方式存在内存泄漏的问题，当过期键一致没有访问将无法得到及时删除，从而导致内存不能及时释放，因此，redis提供了另一种定时任务删除机制作为惰性删除的补充</p>
<p><strong>b、定时任务删除：</strong></p>
<p>redis内部维护一个定时任务，默认每秒运行10次（可以通过配置hz控制）。定时任务中删除过期键逻辑采用自适应算法，根据键的过期比例，适用快慢两种速率模式回收键，流程如下：</p>
<p>i、定时任务在每个数据库空间随机检查20个键，当发现键过期时，删除对应的键</p>
<p>ii、如果超过检查数25%的键过期，循环执行回收逻辑只到不足25%或运行超时为止啊，慢模式下超市时间为25ms</p>
<p>iii、如果之前回收键逻辑超时，则在redis触发内部事件之前再次以快模式运行回收过期键任务，快模式下超时时间为1ms且2s内只能运行1次</p>
<p>iv、快慢两种模式内部删除逻辑相同，只是执行的超时时间不同</p>
<h3 id="2）内存溢出控制策略"><a href="#2）内存溢出控制策略" class="headerlink" title="2）内存溢出控制策略"></a>2）内存溢出控制策略</h3><p>当redis所用内存达到maxmemory上限时会触发相应的溢出控制策略，具体策略手maxmemory-policy参数控制</p>
<p>redis支持六种策略，如下：</p>
<p>a、<strong>noeviction</strong>：redis的默认策略，不会删除任何数据，拒绝所有写入操作并返回客户端错误信息，此时redis只响应读操作</p>
<p>b、<strong>volatile-lru</strong>：根据LRU算法删除设置了超时属性的键，直到腾出足够空间为止。如果没有可删除的键对象，会推倒noeviction策略</p>
<p>c、<strong>allkeys-lru</strong>：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止</p>
<p>d、<strong>allkeys-random</strong>：随机删除所有键，直到腾出足够内存为止</p>
<p>e、<strong>volatile-random</strong>：随机删除过期键，直到腾出足够内存为止</p>
<p>f、<strong>volatile-ttl</strong>：根据键值对象的ttl属性，删除最近将要过期的数据。如果没有，回退到noeviction策略</p>
<h1 id="三、内存优化"><a href="#三、内存优化" class="headerlink" title="三、内存优化"></a>三、内存优化</h1><h2 id="1、redisObject对象"><a href="#1、redisObject对象" class="headerlink" title="1、redisObject对象"></a>1、redisObject对象</h2><p>redis存储的所有值对象在内部定义为redisObject结构体，redis存储的数据都是使用redisObject来封装，包括string、hash、set、zset、list在内的所有数据类型，redisObject对象包括以下几个字段：</p>
<p>1）type字段：表示当前对象使用的数据类型</p>
<p>2）encoding字段：表示redis内部编码类型</p>
<p>3）lru字段：记录对象最后一次被访问的时间，当配置了maxmemory和maxmemory-policy=volatile-lru或者allkeys-lru时，用于辅助LRU算法删除键数据</p>
<p>4）refcount字段：记录当前对象被引用的次数，用于通过引用次数回收内存，当refcount=0时，可以安全回收当前对象空间</p>
<p>5）*ptr字段：与对象的数据内容有关，如果时证书，直接存储数据；否则表示指向数据的指针</p>
<h2 id="2、缩减键值对象"><a href="#2、缩减键值对象" class="headerlink" title="2、缩减键值对象"></a>2、缩减键值对象</h2><p> 降低redis内存使用最直接的方式就是缩减键和值的长度</p>
<ul>
<li>key长度：在设计键时，在完整描述业务情况下，key越短越好</li>
<li>value长度：可以把业务对象序列化成二进制数组放入缓存中，但是在使用的过程中要考虑频繁压缩解压计算所带来的开销成本</li>
</ul>
<h2 id="3、共享对象池"><a href="#3、共享对象池" class="headerlink" title="3、共享对象池"></a>3、共享对象池</h2><p>共享对象池是指redis内部维护[0-9999]的整数对象池</p>
<p>当设置maxmemory并启用LRU相关淘汰策略时redis禁止使用共享对象池。LRU算法需要获取对象最后被访问的时间，以便淘汰最长未访问的数据，每个对象最后访问时间存储在redisObject对象的lru字段。对象共享意味着多个引用共享同一个redisObject，这时lru字段也会被共享，导致无法获取每个对象的最后访问时间。如果没有设置maxmemory，直到内存被用尽redis也不会出发内存回收，所以共享对象池可以工作</p>
<p>为什么只有整数共享对象池？</p>
<p>首先整数对象复用的几率大，其次对象共享的一个关键操作就是判断相等性，redis之所以只有整数对象池，是因为整数比较算法的时间复杂度为<em>O(1)</em>,只保留一万个整数位了防止对象池浪费。</p>
<h2 id="4、字符串优化"><a href="#4、字符串优化" class="headerlink" title="4、字符串优化"></a>4、字符串优化</h2><p>//</p>
<h2 id="5、控制键的数量"><a href="#5、控制键的数量" class="headerlink" title="5、控制键的数量"></a>5、控制键的数量</h2>
        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.143Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/redis学习之客户端" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <h1 id="一、客户端API"><a href="#一、客户端API" class="headerlink" title="一、客户端API"></a>一、客户端API</h1><h2 id="1、client-list"><a href="#1、client-list" class="headerlink" title="1、client list"></a>1、client list</h2><p>client list命令能列出与redis服务端相连的所有客户端连接信息</p>
<p>输出结果的每一行代表已饿客户端信息，可以看到每行包含了十几个属性，常见的如下：</p>
<h3 id="1）标识："><a href="#1）标识：" class="headerlink" title="1）标识："></a>1）标识：</h3><p>id、addr、fd、name 这四个 标示属于客户端标示</p>
<p>a、id：客户端连接的唯一标识，这个id是随着redis的连接自增的，重启redis后会重置为0</p>
<p>b、addr：客户端连接的ip和端口</p>
<p>c、fd：socket的文件描述符，与lsof命令结果中的fd是同一个如果fd=-1代表当前客户端不是外部客户端，而是redis内部的伪装客户端</p>
<p>d、name：客户端的名字，后面的client setName和client getName两个命令会对其进行说明</p>
<h3 id="2）输入缓冲区："><a href="#2）输入缓冲区：" class="headerlink" title="2）输入缓冲区："></a>2）输入缓冲区：</h3><p>qbuf、qbuf-free</p>
<p>redis为每个客户端分配了输入缓冲区，它的作用是将客户端发送的命令临时保存，同时redis会从输入缓冲区拉取命令并执行，输入缓冲区为客户端发送命令到redis执行命令提供了缓冲功能</p>
<p>client list命令中qbuf和qbuf-free分别代表这个缓冲区的总容量和剩余容量，redis没有提供相应的配置来规定每个缓冲区的大小，输入缓冲区会根据输入内容大小的不同动态调整，只是要求每个客户端缓冲区的大小不能超过1G，超过后客户端将被关闭</p>
<p>输入缓冲区使用不当会产生两个问题：</p>
<ul>
<li>一旦某个客户端的输入缓冲区超过1G，客户端将会被关闭。</li>
<li>输入缓冲区不受maxmemory控制，假设一个redis实例设置了maxmemory为4G，已经存储了2G数据，但是如果此时输入缓冲区使用了3G，已经超过maxmemory限制，可能会产生数据丢失、键值淘汰、OOM等情况</li>
</ul>
<p>造成输入缓冲区过大的原因有哪些：</p>
<ul>
<li>redis的处理速度跟不上输入缓冲区的输入速度，并且每次进入输入缓冲区的命令包含了大量的bigkey</li>
<li>redis发生了阻塞，短期内不能处理命令，造成了客户端输入的命令积压在了输入缓冲区</li>
</ul>
<h3 id="3）输出缓冲区"><a href="#3）输出缓冲区" class="headerlink" title="3）输出缓冲区"></a>3）输出缓冲区</h3><p>obl、oll、omem</p>
<p>redis为每个客户端分配了输出缓冲区，它的作用是保存命令执行的结果返回给客户端</p>
<p>与输入缓冲区不同，输出缓冲区可以通过client-output-buffer-limit来进行设置，并且输出缓冲区按照客户端的不同分为三种：普通客户端、发布订阅客户端、slave客户端</p>
<p>和输入缓冲区相同的是，输出缓冲区也不会受到maxmemory的限制，如果使用不当同样会造成maxmemory用满产生的数据丢失、键值淘汰、OOM等情况</p>
<p>输出缓冲区由两部分组成：</p>
<ul>
<li>固定缓冲区（16kb）：返回比较小的执行结果</li>
<li>动态缓冲区：返回比较大的结果</li>
</ul>
<p>固定缓冲区使用的是子节数组，动态缓冲区使用的是列表。当固定缓冲区存满后会将redis新的返回结果存放在动态缓冲区的队列中，队列中的每个对象就是每个返回结果</p>
<p>obl：代表固定缓冲区的长度，对象个数</p>
<p>oll：代表动态缓冲区列表的长度，对象个数</p>
<p>omem：代表使用的子节数</p>
<h3 id="4）客户端的存活状态"><a href="#4）客户端的存活状态" class="headerlink" title="4）客户端的存活状态"></a>4）客户端的存活状态</h3><p>client list中的age和idle代表当前客户端已经连接的时间和最近一次空闲的时间，单位为s</p>
<h3 id="5）客户端的限制"><a href="#5）客户端的限制" class="headerlink" title="5）客户端的限制"></a>5）客户端的限制</h3><p>maxclients：用来限制最大客户端的连接数，一旦连接数超过maxclients，新的连接将被拒绝。maxclients默认值为10000，可以通过info clients来查询当前redis的连接数,可以通过config set maxclients对最大客户端连接数进行动态配置</p>
<p>一般来说maxclients=10000在大部分场景下已经绝对够用，但是某些情况由于业务放方使用不当可能存在大量idle连接，无论是从玩过连接的成本还是超过maxclients的后果来说都不是什么好事，因此redis提供了timeout（单位为s）参数来限制连接的最大空闲时间，一旦客户端连接的idle时间超过了timeout，连接将会被关闭</p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.142Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/redis学习之复制" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          
        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.141Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/redis学习之集群" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <h1 id="一、数据分布"><a href="#一、数据分布" class="headerlink" title="一、数据分布"></a>一、数据分布</h1><p>分布式数据库首先要解决的是要把整个数据集按照分区规则映射到多个节点的问题，即把数据集划分到多个节点上，每个节点负责整体数据的一个子集。常见的分区规则有哈希分区和顺序分区两种。Redis采用的是哈希分区</p>
<p>哈希分区一般分为以下几种：</p>
<p>1、节点取余分区：</p>
<p>使用特定的数据，如redis的键或用户ID，再根据节点数量N使用公式$hash(key)$%$N$计算出哈希值，用来决定数据映射到哪一个节点上。</p>
<p>缺点：当节点数量变化时，如扩容或收缩节点，数据节点映射关系需要重新计算，会导致数据的重新迁移</p>
<p>优点：简单，常用于数据库的分库分表规则，一般采用预分区的方式，提前根据数据量规划好分区数</p>
<p>2、一致性哈希</p>
<p>一致性哈希分区实现思路是为系统中每个节点分配一个token，范围一般在0～2^32^，这些token构成一个哈希环。数据读写执行节点查找操作时，现根据key计算哈希值，然后顺时针找到第一个大于等于该哈希值的token节点</p>
<p>优点：这宗方式相比节点取余最大的好处在于加入和删除节点只影响哈希环中相邻的节点，对其它节点无影响</p>
<p>缺点： </p>
<ul>
<li>加减节点会造成哈希环中部分数据无法命中，需要手动处理或者忽略这部分数据，因此一致性哈希常用于缓存场景</li>
<li>当使用少量节点时，节点变化将大范围影响哈希环中的数据映射，因此这种方式不适合少量数据节点的分布式方案</li>
<li>普通的一致性哈希分区在增减节点时需要增加一倍或减去一半节点才能保证数据和负载的均衡</li>
</ul>
<p>3、虚拟槽分区</p>
<p> 虚拟槽分区使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数集合中，整数定义为槽。这个范围一般远大于节点数，比如redis Cluster槽范围为0～16383.槽时集群内数据管理和迁移的基本单位。采用大范围槽主要目的是问了方便数据拆分和集群扩展</p>
<p>redis数据分区： </p>
<p>redis cluster采用虚拟槽分区，所有的键根据哈希函数映射到0～16383整数槽内，计算公式：$slot=CRC(key)$&amp;$16383$。每一个节点负责维护一部分槽以及槽所映射的键值数据</p>
<p>redis虚拟槽分区的特点：</p>
<ul>
<li>解耦数据和节点之间的关系，简化了节点扩容和收缩的难度</li>
<li>节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据</li>
<li>支持节点、槽、键之间的映射查询，用于数据路由、在线伸缩等场景 </li>
</ul>
<p>集群功能的一些限制：</p>
<p>1、key批量操作支持有限，只支持具有相同slot值的key执行批量操作</p>
<p>2、只支持同一个节点上的多个key的事物操作</p>
<p>3、key作为数据分区的最小力度，因此不能将一个大的键值对象如hash、list等映射到不同的节点</p>
<p>4、不支持多数据库空间，单机下redis可以支持16个数据库，集群模式下只能支持一个数据库空间，也就是db 0</p>
<p>5、复制结构只能支持一层，从节点只能复制主节点，不支持嵌套梳妆复制结构</p>
<h1 id="二、集群配置"><a href="#二、集群配置" class="headerlink" title="二、集群配置"></a>二、集群配置</h1><h2 id="1、节点握手"><a href="#1、节点握手" class="headerlink" title="1、节点握手"></a>1、节点握手</h2><p>节点握手是指一批运行在集群模式下的节点通过Gossip协议彼此通信，达到感知对方的过程</p>
<p>我们只需要在集群内任意节点上执行<code>cluster meet</code>命令加入新节点，握手状态会通过消息在集群内传播，这样其它节点会自动发现新节点并发起握手流程</p>
<p>节点建立握手后集群还不能正常工作，这时集群处于下线状态，所有的数据读写都被禁止,可以通过<code>cluster info</code>命令获取集群的当前状态,因为目前所没有槽被分配到节点，因此集群无法完成槽到节点的映射。只有当16384个槽全部分配给节点之后，集群才进入到在线状态</p>
<h2 id="2、节点握手"><a href="#2、节点握手" class="headerlink" title="2、节点握手"></a>2、节点握手</h2><p>redis集群把所有的数据映射到16384个槽中。每个key会映射为一个固定的槽，只有当前节点分配了槽，才能响应和这些槽关联的键命令。通过<code>cluster addslots</code>命令可以为节点分配槽</p>
<p>作为一个完整的集群，每个负责处理槽的节点应该具有从节点，保证当它出现故障时可以自动进行故障转移。集群模式下，redis节点角色分为主节点和从节点。首次启动的节点和被分配槽的节点都是主节点，从节点负责复制主节点槽信息和相关数据。适用<code>cluster replication [nodeId]</code>命令让一个节点成为从节点。其中命令执行必须在对应的节点上执行，nodeId时要复制主节点的节点ID</p>
<h2 id="3、集群的完整性检查"><a href="#3、集群的完整性检查" class="headerlink" title="3、集群的完整性检查"></a>3、集群的完整性检查</h2><p>集群完整性是指所有的槽都分配到存活的主节点上，只要16384个槽中有一个没有分配给节点则表示集群不完整</p>
<h1 id="三、节点通信"><a href="#三、节点通信" class="headerlink" title="三、节点通信"></a>三、节点通信</h1><p><strong>Gossip协议：</strong>Gossip协议的工作原理就是节点彼此不断通信交换信息，一段时间后所有的节点都会知道集群完整的信息</p>
<h2 id="1、通信流程"><a href="#1、通信流程" class="headerlink" title="1、通信流程"></a>1、通信流程</h2><p>1）集群中的每个节点都会单独开辟一个TCP通道，用于节点之间彼此通信，通信端口号在基础端口上加10000</p>
<p>2）每个节点在固定周期内通过特定规则选择几个节点发送ping消息</p>
<p>3）收到ping消息的节点用pong消息作为响应</p>
<h2 id="2、Gossip消息"><a href="#2、Gossip消息" class="headerlink" title="2、Gossip消息"></a>2、Gossip消息</h2><p>Gossip消息的主要职责就是信息交换。信息交换的载体就是节点彼此发送的Gossip消息，常用的Gossip消息可分为：ping消息、pong消息、meet消息、fail消息等</p>
<p>1）meet消息：用于通知新节点加入集群</p>
<p>2）ping消息：集群内交换最频繁的消息，集群内每个节点每秒向多个其它节点发送ping消息，用于检测节点是否在线和交换彼此状态信息</p>
<p>3）pong消息：当收到ping、meet消息时，作为响应消息回复给发送方确认消息正常通信。pong消息封装了自身的状态数据。节点也可以向集群内广播自身的pong消息来通知整个集群对自身状态进行更新</p>
<p>4）fail消息：当节点判定集群内另一节点下线时，会向集群内广播一个fail消息，其它节点接收到fail消息之后会把对应节点更新为下线状态</p>
<p> 所有的消息格式划分为：消息头和消息题。消息头包含发送节点自身状态数据，接收节点根据消息头就可以获取到发送节点的相关数据</p>
<p><strong>解析消息头过程：</strong></p>
<p>消息头包含了发送节点的信息，如果发送节点时新节点且消息是meet类型，则加入到本地节点列表；如果是已知节点，则尝试更新发送节点的状态，如槽映射关系主从角色等状态</p>
<p><strong>解析消息体过程：</strong></p>
<p>如果消息体的clusterMsgDataGossip数组包含的节点是新节点，则尝试发起与新节点的meet握手流程；如果是已知节点，则根据clusterMsgDataGossip中的flags字段判断该节点是否下线，用于故障转移</p>
<h1 id="四、请求路由"><a href="#四、请求路由" class="headerlink" title="四、请求路由"></a>四、请求路由</h1><h2 id="1、请求重定向"><a href="#1、请求重定向" class="headerlink" title="1、请求重定向"></a>1、请求重定向</h2><p>在集群模式下，redis接收任何键相关命令时首先计算键对应的槽，再根据槽找出所对应的节点，如果节点是自身，则处理键命令；否则回复MOVED重定向错误，通知客户端请求真确的节点。这个过程称为重定向</p>
<p><strong>节点对于不属于它的键命令至回复重定向响应，并不负责转发</strong></p>
<p>键命令执行的步骤主要分两步：计算槽，查找槽所对应的节点 </p>
<p><strong>计算槽：</strong>redis首先需要计算键所对应的槽。根据键的有小部分（若有大括号，就是大括号包围的部分）使用CRC16函数计算出散列值，再取对16383的余数，使每个键都可以映射到0～16383的槽范围内，键内部使用大括号包含的内容叫做hash tag，它提供不同的键可以具备相同slot的功能</p>
<p><strong>槽节点查找：</strong>Jedis的槽定向</p>
<h1 id="五、ASK重定向"><a href="#五、ASK重定向" class="headerlink" title="五、ASK重定向"></a>五、ASK重定向</h1><p>ASK与MOVED虽然都是对客户端的重定向控制，但是有着本质的区别。ASK重定向说明集群正在进行slot数据迁移，客户端无法知道什么时候迁移完成，因此只能是临时性的重定向，客户端不会更新slots缓存。但是MOVED重定向说明键对应的槽已经明确指定到新的节点，因此需要更新slots缓存</p>
<h1 id="六、故障转移"><a href="#六、故障转移" class="headerlink" title="六、故障转移"></a>六、故障转移</h1><p><strong>主观下线：</strong>指某个节点认为另一个节点不可用，即下线状态，这个状态并不是最终的故障判定，只能代表一个节点的意见，可能存在误判的情况</p>
<p><strong>客观下线：</strong>指标记一个节点真正的下线，集群内多个节点都认为该节点不可用，从而达成共识的结果。如果是持有槽的主节点故障，需要为该节点进行故障转移</p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.141Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/redis学习之基础" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <h1 id="一、redis启动命令"><a href="#一、redis启动命令" class="headerlink" title="一、redis启动命令"></a>一、redis启动命令</h1><p>启动redis的三种方法：</p>
<p>1）默认配置：redis-server（生产环境不建议使用）</p>
<p>2）运行启动：redis-server加上要修改的配置名和值（可以是多对），没有设置的配置将使用默认配置。虽然运行配置可以自定义配置，但是如果需要修改的配置较多或者希望将配置保存到文件里，不建议使用这种配置</p>
<p>3）配置文件启动：将要修改的配置写到文件里，这样我们就可以按照下边方式启动</p>
<pre><code># redis-server /opt/redis/redis.conf
</code></pre><p>redis-cli可以使用两种方式连接redis服务器：</p>
<p>1）交互方式：</p>
<pre><code># redis-cli -h {host} -p {port} {command}
</code></pre><p>2)命令方式：</p>
<pre><code># redis-cli -h ip {host} -p {port} {command}
</code></pre><p>第二种需要注意的是，如果没有-h参数，那么默认连接127.0.0.1；如果没有-p，那么默认端口就是6379.</p>
<h1 id="二、redis-api的使用"><a href="#二、redis-api的使用" class="headerlink" title="二、redis api的使用"></a>二、redis api的使用</h1><h2 id="1、redis的一些全局命令"><a href="#1、redis的一些全局命令" class="headerlink" title="1、redis的一些全局命令"></a>1、redis的一些全局命令</h2><p>1）查看所有的键</p>
<pre><code>keys *
</code></pre><p>keys命令会遍历所有的键，所以它的时间复杂度为<em>O</em>(n)，因此，<u>当redis保存大量键时，线上禁止使用</u></p>
<p>2）键总数</p>
<pre><code>dbsize
</code></pre><p>键总数会返回当前数据库中键的总数</p>
<p>dbsize命令在计算键总数时不会遍历所有的键，而是直接获取redis内置的键总数变量，所以dbsize命令的时间复杂度为<em>O</em>(1)</p>
<p>3）检查键是否存在</p>
<pre><code>exists key
</code></pre><p>存在返回1，不存在返回0</p>
<p>4）删除键</p>
<pre><code>del key [key1 ...]
</code></pre><p>成功了就返回删除成功的个数，不存在返回0</p>
<p>5）键过期</p>
<pre><code>expire key seconds
</code></pre><p>超时时间单位为秒</p>
<p>可以用ttl命令查看键的剩余过期时间</p>
<pre><code>ttl key
</code></pre><p>它有三种返回值：</p>
<p>a、大于等于零的整数，键剩余的过期时间</p>
<p>b、-1：键没设置过期时间</p>
<p>c、-2:键不存在</p>
<p>6）键的数据结构类型</p>
<pre><code>type key
</code></pre><p>如果键不存在，则返回none</p>
<h2 id="2、redis数据结构的内部编码"><a href="#2、redis数据结构的内部编码" class="headerlink" title="2、redis数据结构的内部编码"></a>2、redis数据结构的内部编码</h2><p>redis的数据结构包括string、hash、list、set、zset等，这些都是redis对外的数据结构，实际上每种数据结构都有其底层的内部编码实现。这种内部编码实现有两个好处：</p>
<p>1）可以改进内部编码，而对外的数据结构和命令没有影响</p>
<p>2）多种内部编码实现可以在不同场景下发挥各自的优势</p>
<h2 id="3、redis的单线程处理机制"><a href="#3、redis的单线程处理机制" class="headerlink" title="3、redis的单线程处理机制"></a>3、redis的单线程处理机制</h2><p>一条命令从客户端到服务端，不会被立即执行，而是都要进一个队列里，然后才会逐个执行</p>
<p>redis即使在单线程下，其执行速度仍然快，归结于以下几点：</p>
<p>1）纯内存访问，redis将所有的数据放在内存内，而内存的响应时长大约为100ns，这是redis达到每秒万级访问的重要基础</p>
<p>2）非阻塞io，redis使用epoll作为I/O多路复用技术的实现，再加上redis自身的事件处理模型将epoll中的连接、读写、关闭都转换为事件，不在网络I/O上浪费过多的时间</p>
<p>3）单线程避免了线程切换和静态产生的消耗</p>
<p>单线程也是有缺点的，如果某个命令的执行时间过长，会造成其他命令的阻塞，这对于redis这种高性能的服务来说是致命的，所以<u>redis是面向快速执行场景的数据库</u></p>
<h2 id="4、字符串"><a href="#4、字符串" class="headerlink" title="4、字符串"></a>4、字符串</h2><p>字符串可以存储字符串、数字、甚至是二进制，但最大不得超过512MB</p>
<p>常用命令：</p>
<p>1）设置值</p>
<pre><code>set key value [ex seconds] [px milliseconds] [nx|xx]
</code></pre><p>ex seconds：为键设置秒级过期时间</p>
<p>px milliseconds：为键设置毫秒级过期时间</p>
<p>nx：键必须不存在，才可以设置成功，用于添加</p>
<p>xx：键必须存在，才可以设置成功，用于更新</p>
<p>也有专门支持nx的命令setnx，其中setnx可以用来实现分布式锁</p>
<p>2）获取值</p>
<pre><code>get key
</code></pre><p>如果键不存在，则返回nil</p>
<p>3）批量设置值</p>
<pre><code>mset key value [key1 value1 ...]
</code></pre><p>4)批量获取值</p>
<pre><code>mget key [key1 ...]
</code></pre><p>如果分别通过get获取n个键的值，则其消费的时间就是<code>n次get时间=n次网络时间+n次命令时间</code></p>
<p>如果通过mget获取n个键的值，则其消费的时间就是<code>n次get时间=1次网络时间+n次命令时间</code></p>
<p>5）计数</p>
<pre><code>incr key
</code></pre><p>incr用于对值进行自增操作，返回结果有三种情况</p>
<p>a、值不是整数，返回错误</p>
<p>b、值是整数，返回自增后的结果</p>
<p>c、键不存在，返回值为0自增，返回的结果为1</p>
<p>redis的内部技术实现时使用了CAS，CAS对cpu的开销在redis不存在，因为redis是单线程的</p>
<p>6）追加值</p>
<pre><code>append key value
</code></pre><p>向字符串的末尾追加值</p>
<p>7）字符串长度</p>
<pre><code>strlen key
</code></pre><p>字符串的内部编码：</p>
<p>a、int：8个字节的长整型</p>
<p>b、embstr：小于等于39个字节的字符串</p>
<p>c、raw，大于39个字节的字符串</p>
<p>字符串的典型使用场景：</p>
<p>a）缓存功能</p>
<p>b）计数</p>
<p>c）共享Session（需要保证redis是高可用和可扩展的）</p>
<p>d）限速，如用户输入手机验证码，一分钟内输入多少次就不让输入，网站对ip的访问限制也是该道理</p>
<h2 id="5、哈希"><a href="#5、哈希" class="headerlink" title="5、哈希"></a>5、哈希</h2><p>哈希类型指键值本身又是一个键值对结构</p>
<p>常用命令：<br>1）设置值</p>
<pre><code>hset key field value
</code></pre><p>设置成功返回1，反之返回0，redis提供了hsetnx命令，作用同setnx，只是其作用域从key变为field</p>
<p>2）获取值</p>
<pre><code>hget key field
</code></pre><p>3）删除field</p>
<pre><code>hdel key field [field1 ...]
</code></pre><p>删除成功后会返回删除的个数</p>
<p>4）计算field个数</p>
<pre><code>hlen key
</code></pre><p>5）批量设置或获取field-value</p>
<pre><code>hmget key field [field1 ...]
hmset key field value [field1 value1 ...]
</code></pre><p>6)判断field是否存在</p>
<pre><code>hexists key field
</code></pre><p>存在返回1，否则返回0</p>
<p>7）获取所有的field</p>
<pre><code>hkeys key
</code></pre><p>8）获取所有的value</p>
<pre><code>hvals key
</code></pre><p>9）获取所有的field-value</p>
<pre><code>hgetall key
</code></pre><p>内部编码：</p>
<p>a、ziplist（压缩列表）：</p>
<p>​    sum(field)&lt;hash-max-ziplist-entries(默认512个)&amp;&amp;value&lt;hash-max-ziplist-value(默认64字节)</p>
<p>zip使用更加紧凑的结构实现多个元素的连续存储，所以在节省内存方面比hashtable优秀很多</p>
<p>b、hashtable（哈希表）：</p>
<p>当不满足a条件时，会采用hashtable编码，因为此时ziplist的读写效率会下降，而hashtable的读写时间复杂度为<em>O</em>(1)</p>
<p>使用场景：</p>
<p>可以存储一个用户的个人信息</p>
<h2 id="6、列表"><a href="#6、列表" class="headerlink" title="6、列表"></a>6、列表</h2><p>列表类型是用来存储多个有序字符串，列表中的每个字符串称为元素。一个列表中最多可以存储2^32^-1个元素</p>
<p>列表的特点：</p>
<p>a、列表中的元素都是有序的</p>
<p>b、列表中的元素是<strong>可以重复</strong>的</p>
<p>常用命令：</p>
<p>1）添加操作</p>
<p>a、从右边插入元素</p>
<pre><code>rpush key value [value1 ...]
</code></pre><p>b、从左边插入元素</p>
<pre><code>lpush key value [value1 ...]
</code></pre><p>c、向某个元素前或后插入元素</p>
<pre><code>linsert key before|after pivot value
</code></pre><p>linsert命令会从列表中找到等于pivot的元素，在其前或者后插入一个新的元素value</p>
<p>2）查找</p>
<p>a、获取指定范围内的元素列表</p>
<pre><code>lrange key start end
</code></pre><p>list的索引下标有两个特点：</p>
<p>i、索引下标从左到右分别是0到N-1，从右到左分别是-1到-N</p>
<p>ii、<strong>lrange中end选项包含了自身</strong></p>
<p>b、获取列表指定索引下标的元素</p>
<pre><code>lindex key index
</code></pre><p>c、获取列表长度</p>
<pre><code>llen key
</code></pre><p>3）删除</p>
<p>a、从列表左侧弹出元素</p>
<pre><code>lpop key
</code></pre><p>b、从列表右侧弹出</p>
<pre><code>rpop key
</code></pre><p>c、删除指定元素</p>
<pre><code>lrem key count value
</code></pre><p>lrem命令会从列表中找到等于value的元素进行删除，根据count的不同分为三种情况：</p>
<p>i、count&gt;0:从左到右，删除至多count个元素</p>
<p>ii、count&lt;0：从右到左，删除最多count绝对值个元素</p>
<p>iii、count=0:删除所有</p>
<p>d、按照指定范围修剪列表</p>
<pre><code>ltrim key start end
</code></pre><p>4）修改</p>
<p>a、修改指定索引下标的元素</p>
<pre><code>lset key index nowValue
</code></pre><p>5）阻塞操作</p>
<p>阻塞式弹出如下：</p>
<pre><code>blpop key [key1 ...] timeout
brpop key [key1 ...] timeout
</code></pre><p>该操作可能有以下几种情况：</p>
<p>i、列表为空：如果timeout = 3，那么客户端要等到3s后返回，如果timeout=0，那么客户端会一直阻塞等下去，如果在阻塞期间添加了key，客户端立即返回</p>
<p>ii、列表不为空，客户端立即返回</p>
<p>在使用brpop时，有两点需要注意：</p>
<p>i、如果是多个键，那么brpop会从左至右遍历键，一旦有一个键能弹出元素，客户端将立即返回</p>
<p>ii、如果多个客户端对同一个键执行brpop，那么最先执行brpop命令的客户端客户获取到弹出的值</p>
<p>内部编码：</p>
<p>a、ziplist（压缩列表）</p>
<p>​        sum(field)&lt;list-max-ziplist-entries(默认512个)&amp;&amp;value&lt;list-max-ziplist-value(默认64字节)</p>
<p>b、linkedlist（链表）</p>
<p>使用场景：</p>
<p>a、消息队列</p>
<p>可以使用lpush+brpop实现阻塞队列</p>
<p>b、文章列表</p>
<h2 id="7、集合"><a href="#7、集合" class="headerlink" title="7、集合"></a>7、集合</h2><p>集合类型也是用来保存多个字符串元素，但和列表类型不一样的是，集合中不允许有重复元素，并且集合中的元素是无序的，不能通过索引下标获取元素。一个集合最多可以存储2^31^-1个元素</p>
<p>常用命令：</p>
<p>1）集合内操作</p>
<p>a、添加元素</p>
<pre><code>sadd key element [element1 ...]
</code></pre><p>返回的结果是添加成功的元素的个数</p>
<p>b、删除元素</p>
<pre><code>srem key element [element1 ...]
</code></pre><p>返回结果为删除成功元素的个数</p>
<p>c、计算元素的个数</p>
<pre><code>scard key
</code></pre><p>该操作的时间复杂度为<em>O</em>(1)，它不会遍历集合所有元素，而是直接用Redis的内部变量</p>
<p>d、判断元素是否在集合中</p>
<pre><code>sismember key element
</code></pre><p>在集合内返回1，否则返回0</p>
<p>e、随机从集合返回指定个数的元素</p>
<pre><code>srandmember key [count]
</code></pre><p>不指定count，默认返回1个元素</p>
<p>f、从集合随机弹出元素</p>
<pre><code>spop key 
</code></pre><p>与srandmember的区别：</p>
<p>spop命令执行后，元素会将元素从集合中删除，二srandmember不会</p>
<p>g、获取所有元素</p>
<pre><code>smembers key
</code></pre><p>smembers和lrange、hgetall一样，都是比较重的操作，建议用sscan来替代</p>
<p>2）集合间操作</p>
<p>a、求多个集合的交集</p>
<pre><code>sinter key [key1 ...]
</code></pre><p>b、求多个集合的并集</p>
<pre><code>sunion key [key1 ...]
</code></pre><p>取并集会去重</p>
<p>c、求多个集合的差集</p>
<pre><code>sdiff key [key1 ...]
</code></pre><p>d、将交集、并集、差集的结果保存</p>
<pre><code>sinterstore destination key [key1 ...]
sunionstore destination key [key1 ...]
sdiffstore destination key [key1 ...]
</code></pre><p>集合间的运算在元素较多的情况下会比较耗时，所以redis提供了上面三个命令将集合的交集、并集、差集保存在destination key中，其结果也是一个集合类型</p>
<p>内部编码：</p>
<p>1）intset（整数集合）：当集合中的元素都是整数且元素的个数小于512个时，采用此编码</p>
<p>2）hashtable（哈希表）：当集合类型不满足1）时，采用此编码 </p>
<p>使用场景：</p>
<p>a、标签（sadd）：给用户添加标签或者给标签添加用户，这两个操作要在一个事物里运行，防止部分命令失败造成的数据不一致。同时，删除用户的标签以及删除标签下的用户也需要在同一个事物里面运行</p>
<p>b、生成随机数，抽奖（spop/srandmember）</p>
<p>c、社交需求（sadd+sinter）</p>
<h2 id="8、有序集合"><a href="#8、有序集合" class="headerlink" title="8、有序集合"></a>8、有序集合</h2><p>有序集合有如下特点：</p>
<p>a、和集合一样不能有重复元素</p>
<p>b、可以排序，但是它和列表使用索引下标作为排序依据不同的是，它给每个元素设置一个分数（score）作为排序的依据</p>
<p>c、虽然有序集合中不能有重复元素，但是score可以重复</p>
<p>下表是列表、集合、有序集合的异同点</p>
<table>
<thead>
<tr>
<th>数据结构</th>
<th>允许重复</th>
<th>是否有序</th>
<th>有序实现方式</th>
<th>应用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>列表</td>
<td>允许</td>
<td>是</td>
<td>索引下标</td>
<td>时间轴、队列</td>
</tr>
<tr>
<td>集合</td>
<td>否</td>
<td>否</td>
<td>无</td>
<td>标签、社交</td>
</tr>
<tr>
<td>有序集合</td>
<td>否</td>
<td>是</td>
<td>分值</td>
<td>排行榜、社交</td>
</tr>
</tbody>
</table>
<p>常用命令：</p>
<p>1）集合内操作：</p>
<p>a、添加成员</p>
<pre><code>zadd key score member [score1 member1 ...]
</code></pre><p>返回结果为成功添加成员的个数</p>
<p>该命令有两点需要注意：</p>
<p>i、redis 3.2为zadd命令添加了nx、xx、ch、incr四个选项：</p>
<ul>
<li>nx：member必须不存在，才可以设置成功，用于添加</li>
<li>xx：member必须存在，才可以设置成功，用于更新</li>
<li>ch：返回此操作后，有序集合元素和分数发生变化的个数</li>
<li>incr：对score做增加，相当于后面介绍的zincrby</li>
</ul>
<p>ii、有序集合相比集合提供了排序字段，但是也产生了代价，zadd的时间复杂度为<em>O</em>(log(<em>n</em>)),add的时间复杂度为<em>O</em>(1)</p>
<p>b、计算成员的个数</p>
<pre><code>zcard key
</code></pre><p>和集合一样，其时间复杂度为<em>O</em>(1)</p>
<p>c、计算某个成员的分数</p>
<pre><code>zscore key member
</code></pre><p>d、计算成员的排名</p>
<pre><code>zrank key member
zrevrank key member
</code></pre><p>zrank是按照分数从低到高返回排名，zrevrank是按照分数从高到低返回排名（排名从0开始计算）</p>
<p>e、删除成员</p>
<pre><code>zrem key member [member1 ...]
</code></pre><p>返回结果为删除成功的个数</p>
<p>f、增加成员分数</p>
<pre><code>zincrby key increment member
</code></pre><p>返回结果为成员的最新分数</p>
<p>g、返回指定排名范围内的成员</p>
<pre><code>zrange    key start end [withscores]
zrevrange key start end [withscores]
</code></pre><p>zrange是从低到高返回，zrevrange是从高到低返回</p>
<p>h、返回指定分数范围的成员</p>
<pre><code>zrangeByscore    key mix max [withscores] [limit offset count]
zrevrangeByscore key mix max [withscores] [limit offset count]
</code></pre><p>withscores 选项会同时返回每个成员的分数。[limit offset count]选项可以限制输出的起始位置和个数</p>
<p>-inf和+inf分别代表无限小和无限大</p>
<p>指定范围可以支持开区间()和闭区间[]</p>
<p>i、返回指定分数范围成员个数</p>
<pre><code>zcount key min max
</code></pre><p>j、删除指定范围内的升序元素</p>
<pre><code>zremrangebyrank key start end
</code></pre><p>k、删除指定范围分数的成员</p>
<pre><code>zremrangebyscore key min max
</code></pre><p>2）集合间操作：</p>
<p>a、交集</p>
<pre><code>zinterstore destination numkeys key [key1 ...] [weights weight [weight1 ...]] [aggregate sum|min|max]
</code></pre><p>该命令的参数说明如下：</p>
<p>i、destination：交集计算结果保存到这个键</p>
<p>ii、numkeys：需要做交集计算键的个数</p>
<p>iii、key[key1 …]：需要做交集的计算的键</p>
<p>iv、weights weight[weight1 …]：每个键的权重，默认为1</p>
<p>v、aggregate sum|min|max：计算成员交集后，分值可以按照sum、min、max做汇总，默认值为sum</p>
<p>b、并集</p>
<pre><code>zunionstore destination numkeys key [key1 ...] [weights weight [weight1 ...]] [aggregate sum|min|max]
</code></pre><p>参数说明同a</p>
<p>内部编码：</p>
<p>1）ziplist（压缩列表）：元素个数小于128个且每个元素的值的大小小于64字节时，会使用该编码，可以节省内存空间</p>
<p>2）skiplist（跳跃表）：当1）不满足时，会选择该种编码格式</p>
<p>使用场景：排行榜</p>
<p>1）添加用户赞数，可以使用zadd+zincrby</p>
<p>2）取消用户赞数，zrem</p>
<p>3）展示获取赞数最多的十个用户zrevrange</p>
<p>4）展示用户信息以及用户分数，zscore+zrank</p>
<h2 id="9、键管理"><a href="#9、键管理" class="headerlink" title="9、键管理"></a>9、键管理</h2><h3 id="1）单个键管理"><a href="#1）单个键管理" class="headerlink" title="1）单个键管理"></a>1）单个键管理</h3><h4 id="a、键重命名"><a href="#a、键重命名" class="headerlink" title="a、键重命名"></a>a、键重命名</h4><pre><code>rename key newkey
</code></pre><p>如果在rename之前，键newkey已经存在，那么它的值将被覆盖</p>
<p>为了防止被强行rename，redis提供了renamenx命令，确保只有newkey不存在时候才被覆盖，若返回结果为0，则表示没有完成重命名</p>
<p>注意：</p>
<p>i、由于重命名期间会执行del命令删除旧的键，如果键对应的值比较大，会村子阻塞redis的可能，这点不要忽视</p>
<p>ii、如果rename和renamenx中的key和newkey是相同的，在redis3.2之前是可以rename的，之后会报错</p>
<h4 id="b、随机返回一个键"><a href="#b、随机返回一个键" class="headerlink" title="b、随机返回一个键"></a>b、随机返回一个键</h4><pre><code>randomkey
</code></pre><h4 id="c、键过期"><a href="#c、键过期" class="headerlink" title="c、键过期"></a>c、键过期</h4><pre><code>expire key seconds #键在seconds秒后过期
expireat key timestamp #键在秒级时间戳timestamp后过期
</code></pre><p>ttl命令和pttl命令都可以查询键的声誉过期时间，但是pttl精确度更高，可以达到毫秒级别，其有三种返回值：</p>
<p>i、大于等于0的整数：键剩余的过期时间（ttl是秒，pttl是毫秒）</p>
<p>ii、-1:键没有设置过期时间</p>
<p>iii、-2:键不存在</p>
<pre><code>pexpire key milliseconds #键在milliseconds毫秒后过期
pexpireat key milliseconds-timestamp #键在毫秒级时间戳后过期
</code></pre><p>使用redis相关过期命令需要注意以下几点：</p>
<p>i、如果expire key的键不存在，返回结果为0</p>
<p>ii、如果过期时间为负值，键会立即被删除，此时就是del</p>
<p>iii、persist命令可以将键的过期时间清除</p>
<pre><code>persist key
</code></pre><p>==iv、对于字符串类型键，执行set命令会去掉过期时间==</p>
<p>v、redis不支持二级数据结构（例如哈希、列表）内部元素的过期功能</p>
<p>vi、setex命令作为set+expire的组合，不但是原子执行，同时减少了一次网络通讯时间</p>
<h4 id="d、键迁移"><a href="#d、键迁移" class="headerlink" title="d、键迁移"></a>d、键迁移</h4><p>i、move</p>
<pre><code>move key db
</code></pre><p>move命令用于在redis内部进行数据迁移</p>
<p>ii、dump+restore</p>
<pre><code>dump key
restore key ttl value
</code></pre><p>dump+restore可以实现在不同的redis实例之间进行数据迁移的功能，整个恰伊工作分两步：</p>
<p>i）在源redis，dump命令会将键值序列化，格式采用的是RDB格式</p>
<p>ii）在目标redis上，restore命令将上面序列化的值进行复原，其中ttl参数代表过期时间，如果ttl=0，代表没有过期时间</p>
<p>注意：</p>
<p>i）整个迁移过程并非原子性的，而是通过客户端分步完成的</p>
<p>ii）迁移过程是开启了两个客户端连接，所以dump的结果不是在源redis和目标redis之间进行传输</p>
<p>iii、migrate</p>
<pre><code>migrate host port key|&quot;&quot; destination-db timeout [copy] [replace] [keys key [key1 ...]]
</code></pre><p>migrate命令也是用于在redis实例间进行数据迁移的，实际上migrate命令就是将dump+restore+del三个命令进行组合，从而简化了操作流程。migrate命令具有原子性。</p>
<p>该命令和dump+restore的区别：</p>
<p>i）整个过程是原子执行的，不需要在多个redis实例上开启客户端的，只需要在源redis上执行migrate命令即可</p>
<p>ii）migtate命令的数据传输直接在源redis和目标redis上完成的</p>
<p>iii）目标redis完成restore后会发送OK给源redis，源redis接收后会根据migrate对应的选项来决定是否在源redis上删除对应的键</p>
<p>参数说明：</p>
<p>i）host：目标redis的ip地址</p>
<p>ii）port：目标redis的端口</p>
<p>iii）key|“”：如果要迁移一个键，key就是要迁移的键，如果要迁移多个键，则此处是“”</p>
<p>iv）destination-db：目标redis的数据库索引，如果要迁移到0号数据库，则这里就填0</p>
<p>v）timeout）迁移的超时时间，单位为毫秒</p>
<p>vi）[copy]：如果添加此项，迁移后并不删除源键</p>
<p>vii）[replace]：如果添加此项，不管目标redis是否存在该键，都会正常迁移进行数据覆盖</p>
<p>viii）[keys key [key1 …]]：迁移多个键</p>
<p>下表是三种迁移方式的比较</p>
<table>
<thead>
<tr>
<th>命令</th>
<th>作用域</th>
<th>原子性</th>
<th>支持多个键</th>
</tr>
</thead>
<tbody>
<tr>
<td>move</td>
<td>redis实例内部</td>
<td>是</td>
<td>否</td>
</tr>
<tr>
<td>dump+restore</td>
<td>redis实例之间</td>
<td>否</td>
<td>否</td>
</tr>
<tr>
<td>migrate</td>
<td>redis实例之间</td>
<td>是</td>
<td>是</td>
</tr>
</tbody>
</table>
<p>这三种迁移模式中，建议使用第三种进行迁移</p>
<h3 id="2）遍历键"><a href="#2）遍历键" class="headerlink" title="2）遍历键"></a>2）遍历键</h3><h4 id="a、全量遍历键"><a href="#a、全量遍历键" class="headerlink" title="a、全量遍历键"></a>a、全量遍历键</h4><pre><code>keys pattern
</code></pre><p>pattern可以使用glob风格的通配符：</p>
<ul>
<li>*代表匹配任意字符</li>
<li>？代表匹配一个字符</li>
<li>[]代表匹配部分字符，如[1，3]代表匹配1，3，[1-10]代表匹配1到10的任意数字</li>
</ul>
<p>遍历键的使用场景：</p>
<ul>
<li>在一个不对外提供服务的redis从节点上执行，这样不会阻塞到客户端的请求，但是会影响到主从复制</li>
<li>如果确认键值总数却是比较少，可以执行该命令</li>
<li>使用scan命令渐进式的遍历所有键，可以有效防止阻塞</li>
</ul>
<h4 id="b、渐进式遍历"><a href="#b、渐进式遍历" class="headerlink" title="b、渐进式遍历"></a>b、渐进式遍历</h4><pre><code>scan cursor [match pattern] [count number]
</code></pre><p>每次执行scan，可以想象成只扫描一个字典中的一部分键，直到将字典中的所有键遍历完毕，其返回结果是下次遍历scan需要的cursor</p>
<p>参数说明：</p>
<p>i）cursor：必须参数，实际上cursor是一个游标，第一次遍历从0开始，每次scan遍历完都会返回当前游标的值，直到游标值为0，表示遍历结束</p>
<p>ii）match pattren：模式匹配，和keys的模式匹配类似</p>
<p>iii）count number：表明每次要遍历的键的个数，默认是10个，该参数可以适当增大</p>
<p>除了scan外，redis提供了面向哈希类型、集合类型、有序集合的扫描遍历命令，解决诸如hgetall、smembers、zrange可能产生的阻塞问题，对应命令分别是hscan、sscan、zscan，它们的用法和scan类似</p>
<p>渐进式遍历的缺点：如果在scan的过程中有键发生变化（如增加、删除、修改），那么遍历效果可能会碰到如下问题：新增的键可能没有遍历到，遍历出了重复的键等情况。</p>
<h3 id="3）数据库管理"><a href="#3）数据库管理" class="headerlink" title="3）数据库管理"></a>3）数据库管理</h3><p>a、切换数据库</p>
<pre><code>select dbindex
</code></pre><p>dbindex为数据库编号，redis中，一个实例默认为16个数据库，编号从0开始</p>
<p>b、flushdb/flushall</p>
<p>flushdb/flushall用于清除数据库，两者之间的区别是flushdb只清除当前数据库，flushall会清除所有数据库</p>
<p>这两个命令带来的两个问题：</p>
<p>a、flushdb/flushall命令会将所有的数据清除，一旦误操作后果不堪设想，可以rename-command配置规避这个问题</p>
<p>b、如果当前数据库键值对比较多，flushdb/flushall存在阻塞redis的可能性</p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.140Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/redis学习之哨兵" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <h1 id="一、-Redis-Sentinel的高可用性"><a href="#一、-Redis-Sentinel的高可用性" class="headerlink" title="一、 Redis Sentinel的高可用性"></a>一、 Redis Sentinel的高可用性</h1><p>当主节点出现故障时，Redis Sentinel能自动完成<strong>故障发现</strong>和<strong>故障转移</strong>，并通知应用方，从而实现真正的高可用.</p>
<p>Redis Sentinel是一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对数据节点和其余的Sentinel节点进行监控，当它发现节点不可用时，会对节点做下线标识。如果被标识的是主节点，他还会和其他Sentinel节点进行协商，当大多数Sentinel节点都认为主节点不可达时，它们会选举出一个Sentinel节点来完成自动故障转移工作，同时会将这个变化实时通知给Redis应用方。</p>
<p>Redis Sentinel进行故障转移的步骤如下：</p>
<p>1、主节点出现故障，此时从节点与主节点失去连接，主从复制失败</p>
<p>2、每个Sentinel节点通过定期监控发现主节点出现了故障</p>
<p>3、多个Sentinel节点对主节点的故障达成一致，选举出一个Sentinel节点作为领导者负责故障转移</p>
<p>4、Sentinel领导者节点进行故障转移</p>
<p>​    1）选取一个从节点，对其执行<code>slave no one</code>命令使其成为新的主节点</p>
<p>​      2）原来的从节点成为新的主节点后，更新应用方的主节点信息，重新启动应用方</p>
<p>​      3）客户端命令其他从节点去复制新的主节点</p>
<p>​      4）待原来的主节点恢复后，让它去复制新的主节点</p>
<p>Sentinel的作用就是实现了第4步操作的自动化</p>
<p>从上边可以看出，Redis Sentinel具有以下几个功能：</p>
<p>1、<strong>监控</strong>：Sentinel节点会定期监测Redis数据节点、其余Sentinel数据节点是否可达</p>
<p>2、<strong>通知</strong>：Sentinel节点会将故障转移的结果通知给应用方</p>
<p>3、<strong>主节点故障转移</strong>：实现从节点晋升为主节点并维护后续正确的主从关系</p>
<p>4、<strong>配置提供者</strong>：在Redis Sentinel结构中，客户端在初始化的时候连接的是Sentinel节点集合，从中获取主节点信息</p>
<p>Redis Sentinel节点集合是由多个Sentinel节点组成，这样有两个好处：</p>
<p>1、对于节点的故障判断是由多个Sentinel节点共同完成，这样可以有效地防止误判</p>
<p>2、这样即使个别Sentinel节点不可用，整个Sentinel节点集合仍然是健壮的</p>
<h1 id="二、redis哨兵配置说明"><a href="#二、redis哨兵配置说明" class="headerlink" title="二、redis哨兵配置说明"></a>二、redis哨兵配置说明</h1><p>1、sentinel monitor</p>
<pre><code>sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;port&gt; &lt;quorum&gt;
</code></pre><p>该配置说明了Sentinel节点要监控的是一个名字叫&lt; master-name &gt;，ip地址和端口为&lt; ip &gt; &lt; port &gt;的主节点。&lt; quorum &gt;代表要判定主节点最终不可达所需要的票数。但实际上Sentinel节点会对所有的节点进行监控，但是在Sentinel节点的配置中没有看到有关从节点和其余Sentinel节点的配置，那是因为Sentinel节点会从主节点中获取有关从节点以及其余Sentinel节点的相关信息</p>
<p>&lt; quorum &gt;参数用于故障发现和判定，如将quorum配置为2，代表至少有2个Sentinel节点认为主节点不可达，那么这个不可达的判定才是客观的。一般建议将其<strong>设置为Sentinel节点的一半加1</strong>，同时&lt; quorum &gt;还与Sentinel节点的领导者选举有关，至少要有<code>max(quorum,num(sentinels)/2+1)</code>个Sentinel节点参与选举，才能选出领导者Sentinel，从而完成故障转移</p>
<p>2、sentinel down-after-milliseconds</p>
<pre><code>sentinel down-after-milliseconds &lt;master-name&gt; &lt;times&gt;
</code></pre><p> 每个Sentinel节点都要通过定期发送ping命令来判断redis数据节点和其余Sentinel节点是否可达，如果超过了down-after-milliseconds配置的时间且没有有效的回复，则判定节点不可达，&lt; times &gt;单位为毫秒，就是超时时间。</p>
<p>3、sentinel parallel-syncs</p>
<pre><code>sentinel parallel-syncs &lt;master-name&gt; &lt;nums&gt;
</code></pre><p>当Sentinel节点集合对主节点故障判定达成一致时，Sentinel领导者节点会做故障转移操作，选出新的主节点，原来的从节点会向新的主节点发起复制操作，<code>parallel-syncs</code>就是用来限制在一次故障转移之后，每次向新的主节点同时发起复制操作的从节点数，parallel-syncs=3表示三个从节点同时向主节点发起复制操作，parallel-syncs=1表示一个从节点同时向主节点发起复制操作，这个时候会发起轮询复制</p>
<p>4、sentinel failover-timeout</p>
<pre><code>sentinel failover-timeout &lt;master-name&gt; &lt;times&gt;
</code></pre><p>failover-timeout通常被解释成故障转移的超时时间，但实际上它作用于故障转移的各个阶段：</p>
<p>a、选出合适的从节点</p>
<p>b、晋升选出的从节点为主节点</p>
<p>c、命令其余从节点复制新的主节点</p>
<p>d、等待原主节点恢复后命令它去复制新的主节点</p>
<p>failover-timeout的作用具体体现在四个方面：</p>
<p>1）如果Redis Sentinel对一个主节点故障转移失败，那么下次再对该主节点做故障转移的起始时间时failover-timeout的2倍</p>
<p>2）在b阶段时，如果Sentinel节点向a阶段选出来的节点执行<code>slaveof no one</code>操作一直失败（例如该从节点此时出现故障），当过程超过failover-timeout时，则故障转移失败</p>
<p>3）在b阶段如果执行成功，Sentinel节点还会执行info命令确认a阶段选出来的节点确实晋升为主节点，如果此过程执行时间超过failover-timeout时，则故障转移失败</p>
<p>4）如果c阶段执行时间超过了failover-timeout（不包含复制时间），则故障转移失败，注意即使超过了这个时间，Sentinel节点也会最终配置从节点去同步最新的主节点</p>
<p>5、sentinel auth-pass</p>
<pre><code>sentinel auth-pass &lt;master-name&gt; &lt;password&gt;
</code></pre><p>如果Sentinel监控的主节点配置了密码，sentinel auth-pass配置通过添加主节点的密码，防止Sentinel节点对主节点无法监控</p>
<p>6、sentinel notification-script</p>
<pre><code>sentinel notification-script &lt;master-name&gt; &lt;script-path&gt;
</code></pre><p>Sentinel notification-script的作用是在故障转移期间，当一些警告级别的Sentinel时间发生（指重要事件，例如-sdown：客观下线，-odown：主观下线）时，会触发对应路径的脚本，并向脚本发送相应的事件参数作为邮件或者短信报警依据</p>
<p>7、sentinel client-reconfig-script</p>
<pre><code>sentinel client-reconfig-script &lt;master-name&gt; &lt;script-path&gt;
</code></pre><p>Sentinel client-reconfig-script的作用时在故障转移结束后，会触发对应路径的脚本，并向脚本发送故障转移结果的相关参数，该脚本会接收每个Sentinel节点传过来的故障转移结果参数，并触发类似短信或邮件报警</p>
<p>监控多个主节点：</p>
<p>Sentinel监控多个主节点的配置就是只需要指定多个masterName来区分不同的节点即可</p>
<h1 id="三、客户端连接"><a href="#三、客户端连接" class="headerlink" title="三、客户端连接"></a>三、客户端连接</h1><p>实现一个Sentinel客户端的基本步骤：</p>
<p>1、遍历Sentinel节点集合获取一个可用的Sentinel节点</p>
<p>2、通过<code>sentinel get-master-addr-by-name maserName</code>这个API获取对应主节点的相关信息</p>
<p>3、验证当前获取的主节点是真正的主节点（使用<code>role</code>或者<code>info replication</code>命令），这样做的目的是为了防止故障转移期间主节点的变化</p>
<p>4、保持和Sentinel节点集合的联系，时刻获取关于主节点的相关信息</p>
<h1 id="四、Sentinel的实现原理"><a href="#四、Sentinel的实现原理" class="headerlink" title="四、Sentinel的实现原理"></a>四、Sentinel的实现原理</h1><h2 id="1、三个定时监控任务"><a href="#1、三个定时监控任务" class="headerlink" title="1、三个定时监控任务"></a>1、三个定时监控任务</h2><p>1）每隔10s，每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构</p>
<p>这个定时任务的命令：</p>
<ul>
<li>通过向主节点执行info命令，获取从节点的信息，这也是为什么Sentinel节点不需要显式配置基恩孔从节点的原因</li>
<li>当有新的从节点加入时都可以立刻感知出来</li>
<li>节点不可达或者故障转移后，可以通过info命令实时更新节点的拓扑信息</li>
</ul>
<p>2）每隔2秒，每隔Sentinel节点会向redis数据节点<code>__sentin__:hello</code>频道上发送Sentinel节点对于主节点的判断以及当前Sentinel节点的信息，同时每隔Sentinel节点也会订阅该频道，来了解其它Sentinel节点以及它们对主节点的判断，所以这个订单任务可以完成以下两个操作：</p>
<ul>
<li>发现新的Sentinel节点</li>
<li>Sentinel节点之间交换主节点的状态，作为后面客观下线以及领导者选举的依据</li>
</ul>
<p>3）每隔1秒，每个Sentinel节点后向主节点、从节点、其余Sentinel节点发送一条ping命令做一次心跳检测，来确认这些节点当前是否可达。</p>
<h2 id="2、主观下线和客观下线"><a href="#2、主观下线和客观下线" class="headerlink" title="2、主观下线和客观下线"></a>2、主观下线和客观下线</h2><h3 id="1）主观下线"><a href="#1）主观下线" class="headerlink" title="1）主观下线"></a>1）主观下线</h3><p>每个Sentinel节点会每隔1秒对主节点、从节点以及其它Sentinel节点发送ping命令做心跳检测，当这些节点超过down-after-milliseconds没有进行有效回复，Sentinel节点就会对该节点做失败判定，这个行为叫做主观下线，主观下线只是当前Sentinel节点的一家之言，存在误判的可能</p>
<h3 id="2）客观下线"><a href="#2）客观下线" class="headerlink" title="2）客观下线"></a>2）客观下线</h3><p> 当Sentinel主观下线的节点是主节点时，该Sentinel节点会通过<code>sentinel is_master-down-by-addr</code>命令向其它Sentinel节点询问对主节点的判断，当超过<quorum>个数，Sentinel节点认为主节点确实有问题，这时候该Sentinel节点会做出客观下线判断</quorum></p>
<p>从节点、Sentinel节点在主观下线后没有后续的故障转移操作</p>
<p>关于sentinel is_master-down-by-addr命令的介绍：</p>
<pre><code>sentinel is_master-down-by-addr &lt;ip&gt; &lt;port&gt; &lt;current_epoch&gt; &lt;runid&gt;
</code></pre><ul>
<li><p>id：主节点IP</p>
</li>
<li><p>port：主节点端口</p>
</li>
<li><p>current_epoch：当前配置纪元</p>
</li>
<li><p>runid：该参数有两种类型，不同类型决定了此API的作用不同</p>
<p>a、当runid 等于“*”时，作用是Sentinel节点直接交换对主节点下线的判定</p>
<p>b、当runid等于当前Sentinel节点的runid时，作用是当前Sentinel节点希望目标Sentinel节点统一自己成为领导者的请求</p>
</li>
</ul>
<h2 id="3、领导者Sentinel节点选举"><a href="#3、领导者Sentinel节点选举" class="headerlink" title="3、领导者Sentinel节点选举"></a>3、领导者Sentinel节点选举</h2><p>Redis使用了Raft算法实现领导者选举</p>
<p>redis Sentinel进行领导者选举的大体思路：</p>
<p>1）每个在线的Sentinel节点都有资格成为领导者，当它确认主节点主观下线时，会向其它Sentinel节点发送<code>sentinel is_master-down-by-addr</code>命令，要求将自己设置为领导者</p>
<p>2）收到命令的Sentinel节点，如果没有统一过其它Sentinel节点的<code>sentinel is_master-down-by-addr</code>命令，将同意该请求，否则拒绝</p>
<p>3）收到命令的Sentinel节点发现自己的票数已经大于等于<code>max(quorum,num(sentinel)/2+1)</code>，那么它将成为领导者</p>
<p>4）如果此过程没有选举出领导者，将进入下一次选举</p>
<p><strong>选举的过程非常快，基本上谁先完成客观下线，谁就是领导者</strong></p>
<h2 id="4、故障转移"><a href="#4、故障转移" class="headerlink" title="4、故障转移"></a>4、故障转移</h2><p>领导者选举出的Sentinel节点负责故障转移，步骤如下：</p>
<p>1）在从节点列表中选出一个节点作为新的主节点，选择方法如下：</p>
<p>​    a、过滤：不健康（主观下线、断线）、5s内没有回复过Sentinel节点ping相应、与主节点失联超过down-milliseconds*10秒</p>
<p>​    b、选择slave-priority（从节点优先级）最高的从节点列表，如果存在则返回，不存在则继续</p>
<p>​    c、选择复制偏移量最大的从节点（复制的最完整），如果存在则返回，不存在则继续</p>
<p>​    d、选择runid最小的从节点</p>
<p>2）Sentinel领导者节点会对第一步选出来的从节点执行slave no one命令让其成为主节点</p>
<p>3）Sentinel领导者节点会向剩余的从节点发送命令，让它们成为新主节点的从节点，复制规则和parallel-syncs参数有关</p>
<p>4）Sentinel节点集合会将原来的主节点更新为从节点，并保持着对其关注，当其恢复ii后命令它去复制新的主节点</p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.139Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-redis/ redis学习之缓存设计" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
      </h3>
      <div class="repo-list-description">
        
          <h1 id="一、缓存的收益和成本"><a href="#一、缓存的收益和成本" class="headerlink" title="一、缓存的收益和成本"></a><strong>一</strong>、缓存的收益和成本</h1><h2 id="1、缓存的收益"><a href="#1、缓存的收益" class="headerlink" title="1、缓存的收益"></a>1、缓存的收益</h2><p>1）加速读写</p>
<p>2、降低后端负载</p>
<h2 id="2、成本"><a href="#2、成本" class="headerlink" title="2、成本"></a>2、成本</h2><p>1）数据不一致性</p>
<p>2）代码维护成本</p>
<p>3）运维成本</p>
<h2 id="3、使用场景"><a href="#3、使用场景" class="headerlink" title="3、使用场景"></a>3、使用场景</h2><p>1）开销大的复杂计算</p>
<p>2、加速请求响应：redis每秒可以完成几万次的读写，并且提供的批量操作可以优化整个IO链的响应时间</p>
<h1 id="二、缓存更新策略"><a href="#二、缓存更新策略" class="headerlink" title="二、缓存更新策略"></a>二、缓存更新策略</h1><h2 id="1、LRU-LFU-FIFO算法剔除"><a href="#1、LRU-LFU-FIFO算法剔除" class="headerlink" title="1、LRU/LFU/FIFO算法剔除"></a>1、LRU/LFU/FIFO算法剔除</h2><p><strong>使用场景：</strong>通常用于缓存使用量超过了预设的最大值的时候</p>
<p><strong>一致性：</strong>最差</p>
<p><strong>维护成本：</strong>只需要配置maxmemory和对应的策略即可</p>
<h2 id="2、超时剔除"><a href="#2、超时剔除" class="headerlink" title="2、超时剔除"></a>2、超时剔除</h2><p><strong>使用场景：</strong>如果业务可以容忍一段时间内，缓存层数据和存储层数据不一致，那么可以设置过期时间。在数据过期后，再从真实数据源获取数据，重新放到缓存病设置过期时间</p>
<p><strong>一致性：</strong>一段时间窗口内存在一致性问题</p>
<p><strong>维护成本：</strong>较低，只需要设置expire过期时间即可</p>
<h2 id="3、主动更新"><a href="#3、主动更新" class="headerlink" title="3、主动更新"></a>3、主动更新</h2><p><strong>使用场景：</strong>应用方对于数据的一致性要求较高，需要在真实数据更新后，立即更新缓存数据</p>
<p><strong>一致性：</strong>一致性最高，但如果主动更新发生了问题，那么这条数据很可能很长时间不会更新，所以建议结合超市剔除一起使用效果会更好</p>
<p><strong>维护成本：</strong>维护成本比较高，开发需要自己来完成更新，病保证更新操作的正确性</p>
<h2 id="4、最佳实践"><a href="#4、最佳实践" class="headerlink" title="4、最佳实践"></a>4、最佳实践</h2><ul>
<li>低一致性业务建议配置最大内存和淘汰策略方式使用</li>
<li>高一致性业务可以结合使用超时剔除和主动更新，这样即使更新出了问题，也能保证数据过期时间后删除脏数据</li>
</ul>
<h1 id="二、穿透优化"><a href="#二、穿透优化" class="headerlink" title="二、穿透优化"></a>二、穿透优化</h1><p>缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，通常处于容错的考虑，如果从存储层查不到数据则不写入缓存层</p>
<p>造成缓存穿透的原因有两个</p>
<ul>
<li>自身业务代码或者数据出现问题</li>
<li>一些恶意攻击、爬虫等造成大量空命中</li>
</ul>
<p>解决缓存穿透问题的几个方案：</p>
<p><strong>1、缓存空对象：</strong>如果存储层不命中，则仍然将空对象保留到缓存层中，之后再访问这个数据将会从缓存中获取，这样就保护了后端数据源</p>
<p>缓存空对象会有连个问题：</p>
<ul>
<li>空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间（如果是攻击，问题更严重），比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除</li>
<li>缓存层和存储层的数据会有一段时间窗口不一致，可能会对业务有一定的影响</li>
</ul>
<p><strong>2、布隆过滤器拦截：</strong>在访问缓存层和存储层之前，讲存在的key用布隆过滤器提前保存起来，做一层拦截，redis可以利用Bitmaps实现布隆过滤器</p>
<p>这种方式适用于数据命中不高，数据相对固定，实时性较低的应用场景，代码维护较为复杂，但是缓存空间占用小</p>
<h1 id="三、无底洞优化"><a href="#三、无底洞优化" class="headerlink" title="三、无底洞优化"></a>三、无底洞优化</h1><p>所谓无底洞，就是说投入的越多不一定产出越多</p>
<h2 id="1、常见的IO优化思路"><a href="#1、常见的IO优化思路" class="headerlink" title="1、常见的IO优化思路"></a>1、常见的IO优化思路</h2><ul>
<li>命令本身的优化，例如优化SQL语句</li>
<li>减少网络通信次数</li>
<li>降低接入成本，例如客户端使用长连接/连接池、NIO等</li>
</ul>
<p><strong>几种批量操作解决方案对比</strong></p>
<table>
<thead>
<tr>
<th>方案</th>
<th>优点</th>
<th>缺点</th>
<th>网络IO</th>
</tr>
</thead>
<tbody>
<tr>
<td>串行命令</td>
<td>1）编程简单<br>2)如果少量 keys，性能可以满徐需求</td>
<td>大量keys请求延迟严重</td>
<td><em>O</em>(keys)</td>
</tr>
<tr>
<td>串行IO</td>
<td>1）编程简单<br>2）少量节点，性能满足需求</td>
<td>大量node延迟严重</td>
<td><em>O</em>(nodes)</td>
</tr>
<tr>
<td>并行IO</td>
<td>利用并行特性，延迟取决于最慢的节点</td>
<td>1）编程复杂<br>2）由于多线程，问题定位可能较难</td>
<td><em>O</em>(max_slow(nodes))</td>
</tr>
<tr>
<td>hash_tag</td>
<td>性能最高</td>
<td>1）业务维护成本较高<br>2）容易出现数据倾斜</td>
<td><em>O</em>(1)</td>
</tr>
</tbody>
</table>
<h1 id="四、雪崩优化"><a href="#四、雪崩优化" class="headerlink" title="四、雪崩优化"></a>四、雪崩优化</h1><p>由于缓存层承载着大量请求，有效地保护了存储层，但是如果缓存层由于某些原因不能提供服务，于是所有的请求都会达到存储层，存储层的调用量会暴增，造成存储层也会级联当即的情况</p>
<p>预防和解决缓存雪崩的问题，可以从以下几方面着手：</p>
<p>1、保证缓存层服务的高可用性</p>
<p>2、依赖隔离组件为后端限流并降级</p>
<p>3、提前演练</p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T11:02:13.138Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
                  <article id="post-hello-world" class="repo-list">
    <div class="repo-list-item">
      <h3 class="repo-list-name" itemprop="name">
        
  
      <a class="article-title" href="/2019/01/13/hello-world/">Hello World</a>
  

      </h3>
      <div class="repo-list-description">
        
          <p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p>
<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><pre><code class="bash">$ hexo new &quot;My New Post&quot;
</code></pre>
<p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p>
<h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><pre><code class="bash">$ hexo server
</code></pre>
<p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p>
<h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><pre><code class="bash">$ hexo generate
</code></pre>
<p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p>
<h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><pre><code class="bash">$ hexo deploy
</code></pre>
<p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>

        
      </div>
      <p class="repo-list-meta">
        <span class="meta-info">
          <span class="octicon octicon-calendar"></span>
           <time datetime="2019-01-13T10:31:26.030Z" itemprop="datePublished">2019-01-13</time>
        </span>

        
      
        <!--
          
        -->

      </p>
    </div>
  </article>
            
        </div>
        <div class="column one-third">
          <!--处理未安装 search 插件 默认 Google 搜索-->
 

<h3>Search</h3>

<div id="site_search">

	<!-- Google -->
	

	<!-- 本地搜索 -->
	
		<form id="search-form">
			<input type="text" id="search" placeholder="Search">
			<button type="button" class="btn btn-default" id="site_search_do"><span class="octicon octicon-search"></span></button>
		</form>

		<div id="local-search-result"></div>

		<script src="/js/search.js"></script>	
		<script type="text/javascript">
			$(function(){
				var currentIndex = -1;
				var search_path = "search.xml";
				if (!search_path) search_path = "search.xml";
				var path = "/" + search_path;
				searchFunc(path, 'search', 'local-search-result');

				$(document).delegate("#local-search-result>.search-result-list li","hover",function(){
					var liNode = $("#local-search-result>.search-result-list li");
					liNode.removeClass("hover");
					currentIndex = $("#local-search-result>.search-result-list li").index($(this));
					liNode.eq(currentIndex).addClass("hover");
				})

				$("#search-form").submit(function(){
					return false;
				})

				$("#search").keydown(function(event){
					var keyCode = event.keyCode;
					var liNode = $("#local-search-result>.search-result-list li");
					if(keyCode == 38 || keyCode == 40 || keyCode == 13){
						liNode.removeClass("hover");
						if(keyCode == 38){
							if(currentIndex - 1 >= 0) currentIndex --;
						}
						if(keyCode == 40){
							if(currentIndex + 1 < liNode.length) currentIndex ++;
						}
						if(keyCode == 13){
							location.href = liNode.eq(currentIndex).find("a").attr("href");
						}
						liNode.eq(currentIndex).addClass("hover");
						return false;
					}else{
						currentIndex = -1;
					}
				})
			})
		</script>

	

</div>

<h3>Popular Repositories</h3>
    <div class="popular-container"></div>
    
    <script type="text/template" id="popular-list-template">
        <a href="{%=clone_url%}" class="card text-center" target="_blank">
            <div class="thumbnail">
                <div class="card-image geopattern" data-pattern-id="{%=name%}">
                    <div class="card-image-cell">
                        <h3 class="card-title">
                            {%=name%}
                        </h3>
                    </div>
                </div>
                <div class="caption">
                    <div class="card-description">
                        <p class="card-text">
                            {%=description%}
                        </p>
                    </div>
                    <div class="card-text">
                        <span class="meta-info tooltipped tooltipped-n" aria-label="{%=stargazers_count%} stars">
                            <span class="octicon octicon-star"></span> {%=stargazers_count%}
                        </span>
                        <span class="meta-info tooltipped tooltipped-n" aria-label="{%=forks_count%} forks">
                            <span class="octicon octicon-git-branch"></span> {%=forks_count%}
                        </span>
                        <span class="meta-info tooltipped tooltipped-n" aria-label="最后更新时间：{%=updated_at%}">
                            <span class="octicon octicon-clock"></span>
                            <time datetime="{%=updated_at%}">{%=updated_at%}</time>
                        </span>
                    </div>
                </div>
            </div>
        </a>
    </script>

    <script src="/js/baiduTemplate.js"></script>
    <script type="text/javascript">
        var popular_repos = function(){

            var baiduTpl = new Object();

            var handleTpl = function(){
                baiduTpl.popular_list = baidu.template("popular-list-template");
            };

            var handleGithub = function(){
                var popularContainer = $(".popular-container");

                var repos = "hexo-theme-primer".split(",");
                for(var i in repos){
                    var name = repos[i];
                    $.get("https://api.github.com/repos/lixiaojiee/"+name,handle);
                }

                function handle(result){
                    result.updated_at = result.updated_at.split("T")[0];
                    if(result){
                        var html = baiduTpl.popular_list(result);
                        popularContainer.append(html);
                        $(".geopattern").each(function(){           
                            $(this).geopattern($(this).data('pattern-id'));
                        });
                    }
                }
            };

            return {
                init:function(){
                    handleTpl();
                    handleGithub();
                }
            }
        }; 
        $(popular_repos().init);
    </script>

        </div>
    </div>

    
</section>
</body>
<footer class="container">
    <div class="site-footer" role="contentinfo">
        <div class="copyright left mobile-block">
                © 2016
                <span title="yumemor">yumemor</span>
                <a href="javascript:window.scrollTo(0,0)" class="right mobile-visible">TOP</a>
        </div>

        <ul class="site-footer-links right mobile-hidden">
            <li>
                <a href="javascript:window.scrollTo(0,0)">TOP</a>
            </li>
        </ul>

        <a href="https://github.com/yumemor/hexo-theme-primer" target="_blank" aria-label="view source code">
            <span class="mega-octicon octicon-mark-github" title="GitHub"></span>
        </a>

        <ul class="site-footer-links mobile-hidden">
            
                  
                  <li>
                    <a href="/" title="主页">主页</a>
                  </li>
            
                  
                  <li>
                    <a href="/categories/" title="分类">分类</a>
                  </li>
            
                  
                  <li>
                    <a href="/message/" title="留言">留言</a>
                  </li>
            
            <li>
                <a href="/atom.xml">
                    <span class="octicon octicon-rss" style="color:orange;"></span>
                </a>
            </li>
        </ul>
    </div>
</footer>

		<script src="/js/geopattern.js"></script>
		<script src="/js/highlight.pack.js"></script>
		<script src="/lib/fancybox/jquery.fancybox-1.3.4.pack.js"></script>

		

		<script src="/js/index.js"></script>

		 <script src="/js/popular_repo.js"></script> 

	
